{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN (U-NET Below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/romain/anaconda/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import matplotlib.image as mpimg\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import matplotlib.colors as colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(infilename):\n",
    "    data = mpimg.imread(infilename)\n",
    "    return data\n",
    "\n",
    "def img_float_to_uint8(img):\n",
    "    rimg = img - numpy.min(img)\n",
    "    rimg = (rimg / numpy.max(rimg) * PIXEL_DEPTH).round().astype(numpy.uint8)\n",
    "    return rimg\n",
    "\n",
    "def concatenate_images(img, gt_img):\n",
    "    nChannels = len(gt_img.shape)\n",
    "    w = gt_img.shape[0]\n",
    "    h = gt_img.shape[1]\n",
    "    if nChannels == 3:\n",
    "        cimg = numpy.concatenate((img, gt_img), axis=1)\n",
    "    else:\n",
    "        gt_img_3c = numpy.zeros((w, h, 3), dtype=numpy.uint8)\n",
    "        gt_img8 = img_float_to_uint8(gt_img)          \n",
    "        gt_img_3c[:,:,0] = gt_img8\n",
    "        gt_img_3c[:,:,1] = gt_img8\n",
    "        gt_img_3c[:,:,2] = gt_img8\n",
    "        img8 = img_float_to_uint8(img)\n",
    "        cimg = numpy.concatenate((img8, gt_img_3c), axis=1)\n",
    "    return cimg\n",
    "\n",
    "def extract_labels(filename, num_images, stride = IMG_PATCH_SIZE, verbose=1):\n",
    "    \"\"\"Extract the labels into a 1-hot matrix [image index, label index].\"\"\"\n",
    "    gt_imgs = []\n",
    "    for i in range(1, num_images+1):\n",
    "        imageid = \"satImage_%.3d\" % i\n",
    "        image_filename = filename + imageid + \".png\"\n",
    "        if os.path.isfile(image_filename):\n",
    "            if verbose:\n",
    "                print ('Loading ' + image_filename)\n",
    "            img = mpimg.imread(image_filename)\n",
    "            gt_imgs.append(img)\n",
    "        else:\n",
    "            print ('File ' + image_filename + ' does not exist')\n",
    "\n",
    "    num_images = len(gt_imgs)\n",
    "    gt_patches = [img_crop(gt_imgs[i], IMG_PATCH_SIZE, IMG_PATCH_SIZE, stride) for i in range(num_images)]\n",
    "    data = numpy.asarray([gt_patches[i][j] for i in range(len(gt_patches)) for j in range(len(gt_patches[i]))])\n",
    "    labels = numpy.asarray([value_to_class(numpy.mean(data[i])) for i in range(len(data))])\n",
    "    # Convert to dense 1-hot representation.\n",
    "    return labels.astype(numpy.float32)\n",
    "\n",
    "def img_crop(im, w, h, stride):\n",
    "    list_patches = []\n",
    "    imgwidth = im.shape[0]\n",
    "    imgheight = im.shape[1]\n",
    "    is_2d = len(im.shape) < 3\n",
    "    for i in range(0,imgheight-numpy.mod(stride,h),stride):\n",
    "        for j in range(0,imgwidth-numpy.mod(stride,w),stride):\n",
    "            if is_2d:\n",
    "                im_patch = im[j:j+w, i:i+h]\n",
    "            else:\n",
    "                im_patch = im[j:j+w, i:i+h, :]\n",
    "            list_patches.append(im_patch)\n",
    "    return list_patches\n",
    "\n",
    "foreground_threshold = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "\n",
    "def value_to_class(v):\n",
    "    foreground_threshold = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "    df = numpy.sum(v)\n",
    "    if df > foreground_threshold:\n",
    "        return [0, 1]\n",
    "    else:\n",
    "        return [1, 0]\n",
    "        \n",
    "def extract_data(filename, num_images,stride = IMG_PATCH_SIZE, verbose=1):\n",
    "    imgs = []\n",
    "    for i in range(1, num_images+1):\n",
    "        imageid = \"satImage_%.3d\" % i\n",
    "        image_filename = filename + imageid + \".png\"\n",
    "        if os.path.isfile(image_filename):\n",
    "            if verbose:\n",
    "                print ('Loading ' + image_filename)\n",
    "            img = mpimg.imread(image_filename)\n",
    "            imgs.append(img)\n",
    "        else:\n",
    "            print ('File ' + image_filename + ' does not exist')\n",
    "\n",
    "    num_images = len(imgs)\n",
    "    IMG_WIDTH = imgs[0].shape[0]\n",
    "    IMG_HEIGHT = imgs[0].shape[1]\n",
    "    N_PATCHES_PER_IMAGE = (IMG_WIDTH/IMG_PATCH_SIZE)*(IMG_HEIGHT/IMG_PATCH_SIZE)\n",
    "\n",
    "    img_patches = [img_crop(imgs[i], IMG_PATCH_SIZE, IMG_PATCH_SIZE, stride) for i in range(num_images)]\n",
    "    data = [img_patches[i][j] for i in range(len(img_patches)) for j in range(len(img_patches[i]))]\n",
    "    \n",
    "    return numpy.asarray(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_images(filename, num_images,verbose=1):\n",
    "    \n",
    "    imgs = []\n",
    "    for i in range(1, num_images+1):\n",
    "        imageid = \"satImage_%.3d\" % i\n",
    "        image_filename = filename + imageid + \".png\"\n",
    "        if os.path.isfile(image_filename):\n",
    "            if verbose:\n",
    "                print ('Loading ' + image_filename)\n",
    "            img = mpimg.imread(image_filename)\n",
    "            imgs.append(img)\n",
    "        else:\n",
    "            print ('File ' + image_filename + ' does not exist')\n",
    "\n",
    "    num_images = len(imgs)    \n",
    "    return numpy.asarray(imgs)\n",
    "\n",
    "def extract_groundtruth(filename, num_images, verbose=1):\n",
    "    gt_imgs = []\n",
    "    for i in range(1, num_images+1):\n",
    "        imageid = \"satImage_%.3d\" % i\n",
    "        image_filename = filename + imageid + \".png\"\n",
    "        if os.path.isfile(image_filename):\n",
    "            if verbose:\n",
    "                print ('Loading ' + image_filename)\n",
    "            img = mpimg.imread(image_filename)\n",
    "            gt_imgs.append(img)\n",
    "        else:\n",
    "            print ('File ' + image_filename + ' does not exist')\n",
    "\n",
    "    return numpy.asarray(gt_imgs).astype(numpy.float32)\n",
    "\n",
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_rotations(patches,labels):\n",
    "    new_patches = [numpy.rot90(patches[j],i) for i in range(4) for j in range(len(patches))]\n",
    "    new_labels = numpy.repeat(labels,4,axis=0)\n",
    "    return numpy.asarray(new_patches),numpy.asarray(new_labels)\n",
    "\n",
    "def rgb_to_hsv(patches):\n",
    "    new_patches = [colors.rgb_to_hsv(patches[i]) for i in range(len(patches))]\n",
    "    return numpy.asarray(new_patches)\n",
    "\n",
    "def create_bagging_sets(train_data,train_labels,ratio,n):\n",
    "\n",
    "    numpy.random.seed()\n",
    "    \n",
    "    l = numpy.size(train_data,0)\n",
    "    batch_size = int(numpy.floor(ratio*l))\n",
    "    indices = numpy.random.randint(l,size=(n,batch_size))\n",
    "    \n",
    "    data_sets = [train_data[indices[i]] for i in range(n)]\n",
    "    label_sets = [train_labels[indices[i]] for i in range(n)]\n",
    "    \n",
    "    \n",
    "    return numpy.asarray(data_sets), numpy.asarray(label_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "PIXEL_DEPTH = 255\n",
    "TRAINING_SIZE = 100\n",
    "BATCH_SIZE = 16 # 64\n",
    "NUM_EPOCHS = 5\n",
    "BAGGING_SIZE = 3\n",
    "BAGGING_RATIO = 0.5\n",
    "TRAINING_STRIDE = 8\n",
    "\n",
    "# Set image patch size in pixels\n",
    "# IMG_PATCH_SIZE should be a multiple of 4\n",
    "# image size should be an integer multiple of this number!\n",
    "IMG_PATCH_SIZE = 16\n",
    "\n",
    "def prepare_data(verbose=1,stride=TRAINING_STRIDE):\n",
    "\n",
    "    root_dir = \"training/\"\n",
    "    image_dir = root_dir + \"images/\"\n",
    "    gt_dir = root_dir + \"groundtruth/\"\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Extracting data...\")\n",
    "    train_data = extract_data(image_dir, TRAINING_SIZE, stride=stride, verbose=0)\n",
    "    \n",
    "    if verbose:\n",
    "        print('Extracting labels...')\n",
    "    train_labels = extract_labels(gt_dir, TRAINING_SIZE, stride=stride, verbose=0)\n",
    "    \n",
    "    if verbose:\n",
    "        print('Changing color representation')\n",
    "    # Use HSV instead of RGB\n",
    "    train_data  = rgb_to_hsv(train_data)\n",
    "\n",
    "    # Add rotations to make model rotation-invariant\n",
    "    #train_data, train_labels = add_rotations(train_data,train_labels)\n",
    "\n",
    "    if verbose:\n",
    "        print('Spliting data for cross-validation')\n",
    "    # Seperate data for cross-validation\n",
    "    return train_test_split(train_data, train_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "    \n",
    "def create_model(verbose=0):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(16, 16,3), padding='same', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "    sgd = SGD(lr=0.01, momentum=0.9, decay=1e-6, nesterov=False)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    \n",
    "    if verbose:\n",
    "        print(model.summary())\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_models(X_train, X_test, y_train, y_test, bagging_size=3, bagging_ratio=0.4, epochs=5, batch_size=16,verbose=1):\n",
    "    \n",
    "    models = []\n",
    "    \n",
    "    if verbose:\n",
    "        print('Creating bagging data sets...')\n",
    "        \n",
    "    data_sets ,label_sets = create_bagging_sets(X_train, y_train, bagging_ratio, bagging_size)\n",
    "    \n",
    "    for i in range(bagging_size):\n",
    "        \n",
    "        if verbose:\n",
    "            print('\\n Training model n째%d' % int(i+1))\n",
    "            \n",
    "        model = create_model(verbose=0)\n",
    "        model.fit(data_sets[i],label_sets[i],validation_data=(X_test, y_test), epochs=epochs, batch_size=batch_size, verbose = verbose)\n",
    "        models.append(model)\n",
    "    \n",
    "    return models\n",
    "\n",
    "def predict_with_bagging(models, data, labels=[], soft_voting=False, verbose=1):\n",
    "    \n",
    "    if verbose:\n",
    "        print('\\nMaking predictions...')\n",
    "        \n",
    "    n = len(models)    \n",
    "    preds = numpy.asarray([models[i].predict(data, verbose=0) for i in range(n)])\n",
    "    \n",
    "    predictions = numpy.mean(preds,axis=0)\n",
    "    hard_predictions = numpy.zeros(predictions.shape)\n",
    "    \n",
    "    indices = numpy.arange(len(predictions)).reshape((len(predictions),1))\n",
    "    \n",
    "    if soft_voting:\n",
    "        values = numpy.argmax(predictions,1).reshape((len(predictions),1))\n",
    "    else:\n",
    "        values = numpy.rint(numpy.mean(numpy.argmax(preds,2),0)).astype(int).reshape((len(predictions),1))\n",
    "\n",
    "    hard_predictions[indices,values] = 1\n",
    "    \n",
    "    if len(labels):\n",
    "        acc = numpy.count_nonzero(numpy.subtract(hard_predictions,labels))/(2*len(labels))\n",
    "        print(\"Prediction accuracy: %.2f%%\" % ((1-acc)*100))\n",
    "        \n",
    "    return predictions , hard_predictions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating bagging data sets...\n",
      "\n",
      " Training model n째1\n",
      "Train on 96040 samples, validate on 48020 samples\n",
      "Epoch 1/5\n",
      "96040/96040 [==============================] - 152s 2ms/step - loss: 0.4501 - acc: 0.7834 - val_loss: 0.4002 - val_acc: 0.8095\n",
      "Epoch 2/5\n",
      "96040/96040 [==============================] - 175s 2ms/step - loss: 0.3943 - acc: 0.8129 - val_loss: 0.3940 - val_acc: 0.8028\n",
      "Epoch 3/5\n",
      "96040/96040 [==============================] - 176s 2ms/step - loss: 0.3711 - acc: 0.8254 - val_loss: 0.3605 - val_acc: 0.8330\n",
      "Epoch 4/5\n",
      "96040/96040 [==============================] - 146s 2ms/step - loss: 0.3560 - acc: 0.8337 - val_loss: 0.3480 - val_acc: 0.8390\n",
      "Epoch 5/5\n",
      "96040/96040 [==============================] - 161s 2ms/step - loss: 0.3432 - acc: 0.8400 - val_loss: 0.3479 - val_acc: 0.8391\n",
      "\n",
      " Training model n째2\n",
      "Train on 96040 samples, validate on 48020 samples\n",
      "Epoch 1/5\n",
      "96040/96040 [==============================] - 179s 2ms/step - loss: 0.4513 - acc: 0.7837 - val_loss: 0.3951 - val_acc: 0.8134\n",
      "Epoch 2/5\n",
      "96040/96040 [==============================] - 181s 2ms/step - loss: 0.3943 - acc: 0.8132 - val_loss: 0.3773 - val_acc: 0.8223\n",
      "Epoch 3/5\n",
      "96040/96040 [==============================] - 187s 2ms/step - loss: 0.3737 - acc: 0.8242 - val_loss: 0.3629 - val_acc: 0.8337\n",
      "Epoch 4/5\n",
      "96040/96040 [==============================] - 188s 2ms/step - loss: 0.3589 - acc: 0.8327 - val_loss: 0.3661 - val_acc: 0.8318\n",
      "Epoch 5/5\n",
      "96040/96040 [==============================] - 160s 2ms/step - loss: 0.3471 - acc: 0.8402 - val_loss: 0.3495 - val_acc: 0.8415\n",
      "\n",
      " Training model n째3\n",
      "Train on 96040 samples, validate on 48020 samples\n",
      "Epoch 1/5\n",
      "96040/96040 [==============================] - 127s 1ms/step - loss: 0.4494 - acc: 0.7862 - val_loss: 0.4302 - val_acc: 0.7945\n",
      "Epoch 2/5\n",
      "96040/96040 [==============================] - 129s 1ms/step - loss: 0.3965 - acc: 0.8134 - val_loss: 0.3691 - val_acc: 0.8250\n",
      "Epoch 3/5\n",
      "96040/96040 [==============================] - 125s 1ms/step - loss: 0.3735 - acc: 0.8241 - val_loss: 0.3645 - val_acc: 0.8320\n",
      "Epoch 4/5\n",
      "96040/96040 [==============================] - 125s 1ms/step - loss: 0.3579 - acc: 0.8324 - val_loss: 0.3487 - val_acc: 0.8391\n",
      "Epoch 5/5\n",
      "96040/96040 [==============================] - 130s 1ms/step - loss: 0.3456 - acc: 0.8399 - val_loss: 0.3635 - val_acc: 0.8343\n",
      "\n",
      "Making predictions...\n",
      "Prediction accuracy: 84.52%\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = prepare_data()\n",
    "\n",
    "models = train_models(X_train, X_test, y_train, y_test, \n",
    "                      bagging_size=BAGGING_SIZE, bagging_ratio=BAGGING_RATIO, \n",
    "                      epochs=NUM_EPOCHS, batch_size=BATCH_SIZE)\n",
    "\n",
    "preds,hard_preds = predict_with_bagging(models,X_test,y_test,soft_voting = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import matplotlib.image as mpimg\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "from PIL import Image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image(infilename):\n",
    "    data = mpimg.imread(infilename)\n",
    "    return data\n",
    "\n",
    "def img_float_to_uint8(img):\n",
    "    rimg = img - numpy.min(img)\n",
    "    rimg = (rimg / numpy.max(rimg) * PIXEL_DEPTH).round().astype(numpy.uint8)\n",
    "    return rimg\n",
    "\n",
    "def concatenate_images(img, gt_img):\n",
    "    nChannels = len(gt_img.shape)\n",
    "    w = gt_img.shape[0]\n",
    "    h = gt_img.shape[1]\n",
    "    if nChannels == 3:\n",
    "        cimg = numpy.concatenate((img, gt_img), axis=1)\n",
    "    else:\n",
    "        gt_img_3c = numpy.zeros((w, h, 3), dtype=numpy.uint8)\n",
    "        gt_img8 = img_float_to_uint8(gt_img)          \n",
    "        gt_img_3c[:,:,0] = gt_img8\n",
    "        gt_img_3c[:,:,1] = gt_img8\n",
    "        gt_img_3c[:,:,2] = gt_img8\n",
    "        img8 = img_float_to_uint8(img)\n",
    "        cimg = numpy.concatenate((img8, gt_img_3c), axis=1)\n",
    "    return cimg\n",
    "\n",
    "def extract_labels(filename, num_images):\n",
    "    \"\"\"Extract the labels into a 1-hot matrix [image index, label index].\"\"\"\n",
    "    gt_imgs = []\n",
    "    for i in range(1, num_images+1):\n",
    "        imageid = \"satImage_%.3d\" % i\n",
    "        image_filename = filename + imageid + \".png\"\n",
    "        if os.path.isfile(image_filename):\n",
    "            print ('Loading ' + image_filename)\n",
    "            img = mpimg.imread(image_filename)\n",
    "            gt_imgs.append(img)\n",
    "        else:\n",
    "            print ('File ' + image_filename + ' does not exist')\n",
    "\n",
    "    num_images = len(gt_imgs)\n",
    "    gt_patches = [img_crop(gt_imgs[i], IMG_PATCH_SIZE, IMG_PATCH_SIZE) for i in range(num_images)]\n",
    "    data = numpy.asarray([gt_patches[i][j] for i in range(len(gt_patches)) for j in range(len(gt_patches[i]))])\n",
    "    labels = numpy.asarray([value_to_class(numpy.mean(data[i])) for i in range(len(data))])\n",
    "\n",
    "    # Convert to dense 1-hot representation.\n",
    "    return labels.astype(numpy.float32)\n",
    "\n",
    "def img_crop(im, w, h):\n",
    "    list_patches = []\n",
    "    imgwidth = im.shape[0]\n",
    "    imgheight = im.shape[1]\n",
    "    is_2d = len(im.shape) < 3\n",
    "    for i in range(0,imgheight,h):\n",
    "        for j in range(0,imgwidth,w):\n",
    "            if is_2d:\n",
    "                im_patch = im[j:j+w, i:i+h]\n",
    "            else:\n",
    "                im_patch = im[j:j+w, i:i+h, :]\n",
    "            list_patches.append(im_patch)\n",
    "    return list_patches\n",
    "\n",
    "foreground_threshold = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "\n",
    "def value_to_class(v):\n",
    "    foreground_threshold = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "    df = numpy.sum(v)\n",
    "    if df > foreground_threshold:\n",
    "        return [0, 1]\n",
    "    else:\n",
    "        return [1, 0]\n",
    "        \n",
    "def extract_data(filename, num_images):\n",
    "    \"\"\"Extract the images into a 4D tensor [image index, y, x, channels].\n",
    "    Values are rescaled from [0, 255] down to [-0.5, 0.5].\n",
    "    \"\"\"\n",
    "    imgs = []\n",
    "    for i in range(1, num_images+1):\n",
    "        imageid = \"satImage_%.3d\" % i\n",
    "        image_filename = filename + imageid + \".png\"\n",
    "        if os.path.isfile(image_filename):\n",
    "            print ('Loading ' + image_filename)\n",
    "            img = mpimg.imread(image_filename)\n",
    "            imgs.append(img)\n",
    "        else:\n",
    "            print ('File ' + image_filename + ' does not exist')\n",
    "\n",
    "    num_images = len(imgs)\n",
    "    IMG_WIDTH = imgs[0].shape[0]\n",
    "    IMG_HEIGHT = imgs[0].shape[1]\n",
    "    N_PATCHES_PER_IMAGE = (IMG_WIDTH/IMG_PATCH_SIZE)*(IMG_HEIGHT/IMG_PATCH_SIZE)\n",
    "\n",
    "    img_patches = [img_crop(imgs[i], IMG_PATCH_SIZE, IMG_PATCH_SIZE) for i in range(num_images)]\n",
    "    data = [img_patches[i][j] for i in range(len(img_patches)) for j in range(len(img_patches[i]))]\n",
    "\n",
    "    return numpy.asarray(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training/images/satImage_001.png\n",
      "Loading training/images/satImage_002.png\n",
      "Loading training/images/satImage_003.png\n",
      "Loading training/images/satImage_004.png\n",
      "Loading training/images/satImage_005.png\n",
      "Loading training/images/satImage_006.png\n",
      "Loading training/images/satImage_007.png\n",
      "Loading training/images/satImage_008.png\n",
      "Loading training/images/satImage_009.png\n",
      "Loading training/images/satImage_010.png\n",
      "Loading training/images/satImage_011.png\n",
      "Loading training/images/satImage_012.png\n",
      "Loading training/images/satImage_013.png\n",
      "Loading training/images/satImage_014.png\n",
      "Loading training/images/satImage_015.png\n",
      "Loading training/images/satImage_016.png\n",
      "Loading training/images/satImage_017.png\n",
      "Loading training/images/satImage_018.png\n",
      "Loading training/images/satImage_019.png\n",
      "Loading training/images/satImage_020.png\n",
      "Loading training/groundtruth/satImage_001.png\n",
      "Loading training/groundtruth/satImage_002.png\n",
      "Loading training/groundtruth/satImage_003.png\n",
      "Loading training/groundtruth/satImage_004.png\n",
      "Loading training/groundtruth/satImage_005.png\n",
      "Loading training/groundtruth/satImage_006.png\n",
      "Loading training/groundtruth/satImage_007.png\n",
      "Loading training/groundtruth/satImage_008.png\n",
      "Loading training/groundtruth/satImage_009.png\n",
      "Loading training/groundtruth/satImage_010.png\n",
      "Loading training/groundtruth/satImage_011.png\n",
      "Loading training/groundtruth/satImage_012.png\n",
      "Loading training/groundtruth/satImage_013.png\n",
      "Loading training/groundtruth/satImage_014.png\n",
      "Loading training/groundtruth/satImage_015.png\n",
      "Loading training/groundtruth/satImage_016.png\n",
      "Loading training/groundtruth/satImage_017.png\n",
      "Loading training/groundtruth/satImage_018.png\n",
      "Loading training/groundtruth/satImage_019.png\n",
      "Loading training/groundtruth/satImage_020.png\n",
      "(10000, 16, 16, 3) (2500, 16, 16, 3) (10000, 2) (2500, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "NUM_CHANNELS = 3 # RGB images\n",
    "PIXEL_DEPTH = 255\n",
    "NUM_LABELS = 2\n",
    "TRAINING_SIZE = 20\n",
    "VALIDATION_SIZE = 5  # Size of the validation set.\n",
    "SEED = 66478  # Set to None for random seed.\n",
    "BATCH_SIZE = 16 # 64\n",
    "NUM_EPOCHS = 5\n",
    "RESTORE_MODEL = False # If True, restore existing model instead of training a new one\n",
    "RECORDING_STEP = 1000\n",
    "IMG_PATCH_SIZE = 16\n",
    "\n",
    "root_dir = \"training/\"\n",
    "image_dir = root_dir + \"images/\"\n",
    "gt_dir = root_dir + \"groundtruth/\"\n",
    "\n",
    "train_data = extract_data(image_dir, TRAINING_SIZE)\n",
    "train_labels = extract_labels(gt_dir, TRAINING_SIZE)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1 shape: (?, 16, 16, 64)\n",
      "conv1 shape: (?, 16, 16, 64)\n",
      "pool1 shape: (?, 8, 8, 64)\n",
      "conv2 shape: (?, 8, 8, 128)\n",
      "conv2 shape: (?, 8, 8, 128)\n",
      "pool2 shape: (?, 4, 4, 128)\n",
      "conv3 shape: (?, 4, 4, 256)\n",
      "conv3 shape: (?, 4, 4, 256)\n",
      "pool3 shape: (?, 2, 2, 256)\n",
      "(?, 2)\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import Input, merge, Conv2D, MaxPooling2D, UpSampling2D, Dropout, Cropping2D, concatenate, Dense, Flatten\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "\n",
    "\n",
    "input_x = Input(shape=(16, 16,3), name='input_x') \n",
    "conv1 = Conv2D(64, (3,3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(input_x)\n",
    "print(\"conv1 shape:\",conv1.shape)\n",
    "conv1 = Conv2D(64, (3,3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "print(\"conv1 shape:\",conv1.shape)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "print(\"pool1 shape:\",pool1.shape)\n",
    "\n",
    "conv2 = Conv2D(128, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "print(\"conv2 shape:\",conv2.shape)\n",
    "conv2 = Conv2D(128, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "print(\"conv2 shape:\",conv2.shape)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "print(\"pool2 shape:\",pool2.shape)\n",
    "\n",
    "conv3 = Conv2D(256, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "print(\"conv3 shape:\",conv3.shape)\n",
    "conv3 = Conv2D(256, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "print(\"conv3 shape:\",conv3.shape)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "print(\"pool3 shape:\",pool3.shape)\n",
    "\n",
    "conv4 = Conv2D(512, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "conv4 = Conv2D(512, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "drop4 = Dropout(0.5)(conv4)\n",
    "pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "conv5 = Conv2D(1024, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "conv5 = Conv2D(1024, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "#merge6 = merge([drop4,up6], mode = 'concat', concat_axis = 3)\n",
    "merge6 = concatenate([drop4,up6],axis = 3)\n",
    "conv6 = Conv2D(512, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "conv6 = Conv2D(512, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "#merge7 = merge([conv3,up7], mode = 'concat', concat_axis = 3)\n",
    "merge7 = concatenate([conv3,up7], axis = 3)\n",
    "conv7 = Conv2D(256, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "conv7 = Conv2D(256, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "#merge8 = merge([conv2,up8], mode = 'concat', concat_axis = 3)\n",
    "merge8 = concatenate([conv2,up8], axis = 3)\n",
    "conv8 = Conv2D(128, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "conv8 = Conv2D(128, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "#merge9 = merge([conv1,up9], mode = 'concat', concat_axis = 3)\n",
    "merge9 = concatenate([conv1,up9], axis = 3)\n",
    "conv9 = Conv2D(64, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "conv9 = Conv2D(64, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "conv9 = Conv2D(2, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "#conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "#print(conv10.shape)\n",
    "\n",
    "\n",
    "res = Dense(2, activation='sigmoid')(Flatten()(conv9))\n",
    "\n",
    "print(res.shape)\n",
    "model = Model(inputs = input_x, outputs = res) #conv10\n",
    "\n",
    "model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=16, epochs=10, verbose=1,validation_split=0.2, shuffle=True)\n",
    "#model.fit(X_train, y_train, batch_size=16, epochs=10, verbose=1,validation_data=(X_test, y_test), shuffle=True)\n",
    "#print('predict test data')\n",
    "#y_test = model.predict(X_test, batch_size=1, verbose=1)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_to_img(imgwidth, imgheight, w, h, labels):\n",
    "    array_labels = numpy.zeros([imgwidth, imgheight])\n",
    "    idx = 0\n",
    "    for i in range(0,imgheight,h):\n",
    "        for j in range(0,imgwidth,w):\n",
    "            if labels[idx][0] > 0.5:\n",
    "                l = 0\n",
    "            else:\n",
    "                l = 1\n",
    "            array_labels[j:j+w, i:i+h] = l\n",
    "            idx = idx + 1\n",
    "    return array_labels\n",
    "\n",
    "def concatenate_images(img, gt_img):\n",
    "    nChannels = len(gt_img.shape)\n",
    "    w = gt_img.shape[0]\n",
    "    h = gt_img.shape[1]\n",
    "    if nChannels == 3:\n",
    "        cimg = numpy.concatenate((img, gt_img), axis=1)\n",
    "    else:\n",
    "        gt_img_3c = numpy.zeros((w, h, 3), dtype=numpy.uint8)\n",
    "        gt_img8 = img_float_to_uint8(gt_img)          \n",
    "        gt_img_3c[:,:,0] = gt_img8\n",
    "        gt_img_3c[:,:,1] = gt_img8\n",
    "        gt_img_3c[:,:,2] = gt_img8\n",
    "        img8 = img_float_to_uint8(img)\n",
    "        cimg = numpy.concatenate((img8, gt_img_3c), axis=1)\n",
    "    return cimg\n",
    "\n",
    "def bw(gt_img):\n",
    "    nChannels = len(gt_img.shape)\n",
    "    w = gt_img.shape[0]\n",
    "    h = gt_img.shape[1]\n",
    "    if nChannels == 3:\n",
    "        cimg = gt_img #np.concatenate((img, gt_img), axis=1)\n",
    "    else:\n",
    "        gt_img_3c = np.zeros((w, h, 3), dtype=np.uint8)\n",
    "        gt_img8 = img_float_to_uint8(gt_img)          \n",
    "        gt_img_3c[:,:,0] = gt_img8\n",
    "        gt_img_3c[:,:,1] = gt_img8\n",
    "        gt_img_3c[:,:,2] = gt_img8\n",
    "        cimg = gt_img_3c\n",
    "    return cimg\n",
    "\n",
    "    # Get prediction for given input image \n",
    "def get_prediction(img):\n",
    "    data = numpy.asarray(img_crop(img, IMG_PATCH_SIZE, IMG_PATCH_SIZE))\n",
    "    output_prediction = model.predict(data)\n",
    "    img_prediction = label_to_img(img.shape[0], img.shape[1], IMG_PATCH_SIZE, IMG_PATCH_SIZE, output_prediction)\n",
    "\n",
    "    return img_prediction\n",
    "\n",
    "    # Get a concatenation of the prediction and groundtruth for given input file\n",
    "def get_prediction_with_groundtruth(filename, image_idx):\n",
    "    \n",
    "    imageid = \"test_\" + str(image_idx)\n",
    "    image_filename = filename + imageid + \".png\"\n",
    "    img = mpimg.imread(image_filename)\n",
    "    \n",
    "    img_prediction = get_prediction(img)\n",
    "    #cimg = concatenate_images(img, img_prediction)\n",
    "    #cimg = Image.fromarray(bw(img_prediction))\n",
    "\n",
    "    #return cimg\n",
    "    return img_prediction\n",
    "\n",
    "submission_filename = 'submission.csv'\n",
    "image_filenames = []\n",
    "\n",
    "for i in range(1, TRAINING_SIZE+1):\n",
    "    'test_set_images/test_'\n",
    "    test_data_filename = 'test_set_images/test_' + str(i) + '/'\n",
    "    pimg = get_prediction_with_groundtruth(test_data_filename, i)\n",
    "    image_filename = 'test_set_images/pred_' + str(i) + '.png'\n",
    "    Image.fromarray(bw(pimg)).save(image_filename)\n",
    "    print(image_filename)\n",
    "    image_filenames.append(image_filename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
