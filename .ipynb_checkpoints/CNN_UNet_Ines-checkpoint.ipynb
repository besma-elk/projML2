{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN (U-NET Below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import matplotlib.image as mpimg\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import matplotlib.colors as colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATCH_SIZE = 16\n",
    "\n",
    "\n",
    "def load_image(infilename):\n",
    "    data = mpimg.imread(infilename)\n",
    "    return data\n",
    "\n",
    "def img_float_to_uint8(img):\n",
    "    rimg = img - numpy.min(img)\n",
    "    rimg = (rimg / numpy.max(rimg) * PIXEL_DEPTH).round().astype(numpy.uint8)\n",
    "    return rimg\n",
    "\n",
    "def concatenate_images(img, gt_img):\n",
    "    nChannels = len(gt_img.shape)\n",
    "    w = gt_img.shape[0]\n",
    "    h = gt_img.shape[1]\n",
    "    if nChannels == 3:\n",
    "        cimg = numpy.concatenate((img, gt_img), axis=1)\n",
    "    else:\n",
    "        gt_img_3c = numpy.zeros((w, h, 3), dtype=numpy.uint8)\n",
    "        gt_img8 = img_float_to_uint8(gt_img)          \n",
    "        gt_img_3c[:,:,0] = gt_img8\n",
    "        gt_img_3c[:,:,1] = gt_img8\n",
    "        gt_img_3c[:,:,2] = gt_img8\n",
    "        img8 = img_float_to_uint8(img)\n",
    "        cimg = numpy.concatenate((img8, gt_img_3c), axis=1)\n",
    "    return cimg\n",
    "\n",
    "def extract_labels(filename, num_images, stride = IMG_PATCH_SIZE, verbose=1):\n",
    "    \"\"\"Extract the labels into a 1-hot matrix [image index, label index].\"\"\"\n",
    "    gt_imgs = []\n",
    "    for i in range(1, num_images+1):\n",
    "        imageid = \"satImage_%.3d\" % i\n",
    "        image_filename = filename + imageid + \".png\"\n",
    "        if os.path.isfile(image_filename):\n",
    "            if verbose:\n",
    "                print ('Loading ' + image_filename)\n",
    "            img = mpimg.imread(image_filename)\n",
    "            gt_imgs.append(img)\n",
    "        else:\n",
    "            print ('File ' + image_filename + ' does not exist')\n",
    "\n",
    "    num_images = len(gt_imgs)\n",
    "    gt_patches = [img_crop(gt_imgs[i], IMG_PATCH_SIZE, IMG_PATCH_SIZE, stride) for i in range(num_images)]\n",
    "    data = numpy.asarray([gt_patches[i][j] for i in range(len(gt_patches)) for j in range(len(gt_patches[i]))])\n",
    "    labels = numpy.asarray([value_to_class(numpy.mean(data[i])) for i in range(len(data))])\n",
    "    # Convert to dense 1-hot representation.\n",
    "    return labels.astype(numpy.float32)\n",
    "\n",
    "def img_crop(im, w, h, stride):\n",
    "    list_patches = []\n",
    "    imgwidth = im.shape[0]\n",
    "    imgheight = im.shape[1]\n",
    "    is_2d = len(im.shape) < 3\n",
    "    for i in range(0,imgheight-numpy.mod(stride,h),stride):\n",
    "        for j in range(0,imgwidth-numpy.mod(stride,w),stride):\n",
    "            if is_2d:\n",
    "                im_patch = im[j:j+w, i:i+h]\n",
    "            else:\n",
    "                im_patch = im[j:j+w, i:i+h, :]\n",
    "            list_patches.append(im_patch)\n",
    "    return list_patches\n",
    "\n",
    "foreground_threshold = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "\n",
    "def value_to_class(v):\n",
    "    foreground_threshold = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "    df = numpy.sum(v)\n",
    "    if df > foreground_threshold:\n",
    "        return [0, 1]\n",
    "    else:\n",
    "        return [1, 0]\n",
    "        \n",
    "def extract_data(filename, num_images,stride = IMG_PATCH_SIZE, verbose=1):\n",
    "    imgs = []\n",
    "    for i in range(1, num_images+1):\n",
    "        imageid = \"satImage_%.3d\" % i\n",
    "        image_filename = filename + imageid + \".png\"\n",
    "        if os.path.isfile(image_filename):\n",
    "            if verbose:\n",
    "                print ('Loading ' + image_filename)\n",
    "            img = mpimg.imread(image_filename)\n",
    "            imgs.append(img)\n",
    "        else:\n",
    "            print ('File ' + image_filename + ' does not exist')\n",
    "\n",
    "    num_images = len(imgs)\n",
    "    IMG_WIDTH = imgs[0].shape[0]\n",
    "    IMG_HEIGHT = imgs[0].shape[1]\n",
    "    N_PATCHES_PER_IMAGE = (IMG_WIDTH/IMG_PATCH_SIZE)*(IMG_HEIGHT/IMG_PATCH_SIZE)\n",
    "\n",
    "    img_patches = [img_crop(imgs[i], IMG_PATCH_SIZE, IMG_PATCH_SIZE, stride) for i in range(num_images)]\n",
    "    data = [img_patches[i][j] for i in range(len(img_patches)) for j in range(len(img_patches[i]))]\n",
    "    \n",
    "    return numpy.asarray(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images(filename, num_images,verbose=1):\n",
    "    \n",
    "    imgs = []\n",
    "    for i in range(1, num_images+1):\n",
    "        imageid = str(i)\n",
    "        image_filename = filename + imageid + \".png\"\n",
    "        if os.path.isfile(image_filename):\n",
    "            if verbose:\n",
    "                print ('Loading ' + image_filename)\n",
    "            img = mpimg.imread(image_filename)\n",
    "            imgs.append(img)\n",
    "        else:\n",
    "            print ('File ' + image_filename + ' does not exist')\n",
    "\n",
    "    num_images = len(imgs)    \n",
    "    return numpy.asarray(imgs)\n",
    "\n",
    "def extract_groundtruth(filename, num_images, verbose=1):\n",
    "    gt_imgs = []\n",
    "    for i in range(1, num_images+1):\n",
    "        imageid = \"satImage_%.3d\" % i\n",
    "        image_filename = filename + imageid + \".png\"\n",
    "        if os.path.isfile(image_filename):\n",
    "            if verbose:\n",
    "                print ('Loading ' + image_filename)\n",
    "            img = mpimg.imread(image_filename)\n",
    "            gt_imgs.append(img)\n",
    "        else:\n",
    "            print ('File ' + image_filename + ' does not exist')\n",
    "\n",
    "    return numpy.asarray(gt_imgs).astype(numpy.float32)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_rotations(patches,labels):\n",
    "    new_patches = [numpy.rot90(patches[j],i) for i in range(4) for j in range(len(patches))]\n",
    "    new_labels = numpy.repeat(labels,4,axis=0)\n",
    "    return numpy.asarray(new_patches),numpy.asarray(new_labels)\n",
    "\n",
    "def rgb_to_hsv(patches):\n",
    "    new_patches = [colors.rgb_to_hsv(patches[i]) for i in range(len(patches))]\n",
    "    return numpy.asarray(new_patches)\n",
    "\n",
    "def create_bagging_sets(train_data,train_labels,ratio,n):\n",
    "\n",
    "    numpy.random.seed()\n",
    "    \n",
    "    l = numpy.size(train_data,0)\n",
    "    batch_size = int(numpy.floor(ratio*l))\n",
    "    indices = numpy.random.randint(l,size=(n,batch_size))\n",
    "    \n",
    "    data_sets = [train_data[indices[i]] for i in range(n)]\n",
    "    label_sets = [train_labels[indices[i]] for i in range(n)]\n",
    "    \n",
    "    \n",
    "    return numpy.asarray(data_sets), numpy.asarray(label_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "PIXEL_DEPTH = 255\n",
    "TRAINING_SIZE = 100\n",
    "BATCH_SIZE = 16 # 64\n",
    "NUM_EPOCHS = 20\n",
    "BAGGING_SIZE = 3\n",
    "BAGGING_RATIO = 0.5\n",
    "TRAINING_STRIDE = 8\n",
    "\n",
    "# Set image patch size in pixels\n",
    "# IMG_PATCH_SIZE should be a multiple of 4\n",
    "# image size should be an integer multiple of this number!\n",
    "IMG_PATCH_SIZE = 16\n",
    "\n",
    "def prepare_data(verbose=1,stride=TRAINING_STRIDE):\n",
    "\n",
    "    root_dir = \"training/\"\n",
    "    image_dir = root_dir + \"images/\"\n",
    "    gt_dir = root_dir + \"groundtruth/\"\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Extracting data...\")\n",
    "    train_data = extract_data(image_dir, TRAINING_SIZE, stride=stride, verbose=0)\n",
    "    \n",
    "    if verbose:\n",
    "        print('Extracting labels...')\n",
    "    train_labels = extract_labels(gt_dir, TRAINING_SIZE, stride=stride, verbose=0)\n",
    "    \n",
    "    if verbose:\n",
    "        print('Changing color representation')\n",
    "    # Use HSV instead of RGB\n",
    "    train_data  = rgb_to_hsv(train_data)\n",
    "\n",
    "    # Add rotations to make model rotation-invariant\n",
    "    #train_data, train_labels = add_rotations(train_data,train_labels)\n",
    "\n",
    "    if verbose:\n",
    "        print('Spliting data for cross-validation')\n",
    "    # Seperate data for cross-validation\n",
    "    return train_test_split(train_data, train_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "    \n",
    "def create_model(verbose=0):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(16, 16,3), padding='same', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "    sgd = SGD(lr=0.01, momentum=0.9, decay=1e-6, nesterov=False)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    \n",
    "    if verbose:\n",
    "        print(model.summary())\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_models(X_train, X_test, y_train, y_test, bagging_size=3, bagging_ratio=0.4, epochs=5, batch_size=16,verbose=1):\n",
    "    \n",
    "    models = []\n",
    "    \n",
    "    if verbose:\n",
    "        print('Creating bagging data sets...')\n",
    "        \n",
    "    data_sets ,label_sets = create_bagging_sets(X_train, y_train, bagging_ratio, bagging_size)\n",
    "    \n",
    "    for i in range(bagging_size):\n",
    "        \n",
    "        if verbose:\n",
    "            print('\\n Training model n°%d' % int(i+1))\n",
    "            \n",
    "        model = create_model(verbose=0)\n",
    "        model.fit(data_sets[i],label_sets[i],validation_data=(X_test, y_test), epochs=epochs, batch_size=batch_size, verbose = verbose)\n",
    "        models.append(model)\n",
    "    \n",
    "    return models\n",
    "\n",
    "def predict_with_bagging(models, data, labels=[], soft_voting=False, verbose=1):\n",
    "    \n",
    "    if verbose:\n",
    "        print('\\nMaking predictions...')\n",
    "        \n",
    "    n = len(models)    \n",
    "    preds = numpy.asarray([models[i].predict(data, verbose=0) for i in range(n)])\n",
    "    \n",
    "    predictions = numpy.mean(preds,axis=0)\n",
    "    hard_predictions = numpy.zeros(predictions.shape)\n",
    "    \n",
    "    indices = numpy.arange(len(predictions)).reshape((len(predictions),1))\n",
    "    \n",
    "    if soft_voting:\n",
    "        values = numpy.argmax(predictions,1).reshape((len(predictions),1))\n",
    "    else:\n",
    "        values = numpy.rint(numpy.mean(numpy.argmax(preds,2),0)).astype(int).reshape((len(predictions),1))\n",
    "\n",
    "    hard_predictions[indices,values] = 1\n",
    "    \n",
    "    if len(labels):\n",
    "        acc = numpy.count_nonzero(numpy.subtract(hard_predictions,labels))/(2*len(labels))\n",
    "        print(\"Prediction accuracy: %.2f%%\" % ((1-acc)*100))\n",
    "        \n",
    "    return predictions , hard_predictions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data...\n",
      "Extracting labels...\n",
      "Changing color representation\n",
      "Spliting data for cross-validation\n",
      "Creating bagging data sets...\n",
      "\n",
      " Training model n°1\n",
      "Train on 96040 samples, validate on 48020 samples\n",
      "Epoch 1/20\n",
      "96040/96040 [==============================] - 99s 1ms/step - loss: 0.4472 - acc: 0.7857 - val_loss: 0.3978 - val_acc: 0.8110\n",
      "Epoch 2/20\n",
      "96040/96040 [==============================] - 93s 971us/step - loss: 0.3951 - acc: 0.8129 - val_loss: 0.3797 - val_acc: 0.8225\n",
      "Epoch 3/20\n",
      "96040/96040 [==============================] - 94s 976us/step - loss: 0.3749 - acc: 0.8234 - val_loss: 0.3621 - val_acc: 0.8305\n",
      "Epoch 4/20\n",
      "96040/96040 [==============================] - 98s 1ms/step - loss: 0.3604 - acc: 0.8319 - val_loss: 0.3617 - val_acc: 0.8308\n",
      "Epoch 5/20\n",
      "96040/96040 [==============================] - 107s 1ms/step - loss: 0.3480 - acc: 0.8384 - val_loss: 0.3463 - val_acc: 0.8380\n",
      "Epoch 6/20\n",
      "96040/96040 [==============================] - 111s 1ms/step - loss: 0.3378 - acc: 0.8432 - val_loss: 0.3389 - val_acc: 0.8458\n",
      "Epoch 7/20\n",
      "96040/96040 [==============================] - 111s 1ms/step - loss: 0.3288 - acc: 0.8474 - val_loss: 0.3333 - val_acc: 0.8473\n",
      "Epoch 8/20\n",
      "96040/96040 [==============================] - 102s 1ms/step - loss: 0.3212 - acc: 0.8536 - val_loss: 0.3329 - val_acc: 0.8450\n",
      "Epoch 9/20\n",
      "96040/96040 [==============================] - 102s 1ms/step - loss: 0.3131 - acc: 0.8577 - val_loss: 0.3327 - val_acc: 0.8467\n",
      "Epoch 10/20\n",
      "96040/96040 [==============================] - 101s 1ms/step - loss: 0.3060 - acc: 0.8603 - val_loss: 0.3245 - val_acc: 0.8516\n",
      "Epoch 11/20\n",
      "96040/96040 [==============================] - 101s 1ms/step - loss: 0.2984 - acc: 0.8653 - val_loss: 0.3400 - val_acc: 0.8510\n",
      "Epoch 12/20\n",
      "96040/96040 [==============================] - 103s 1ms/step - loss: 0.2927 - acc: 0.8677 - val_loss: 0.3207 - val_acc: 0.8571\n",
      "Epoch 13/20\n",
      "96040/96040 [==============================] - 101s 1ms/step - loss: 0.2868 - acc: 0.8711 - val_loss: 0.3217 - val_acc: 0.8562\n",
      "Epoch 14/20\n",
      "96040/96040 [==============================] - 102s 1ms/step - loss: 0.2813 - acc: 0.8735 - val_loss: 0.3297 - val_acc: 0.8494\n",
      "Epoch 15/20\n",
      "96040/96040 [==============================] - 101s 1ms/step - loss: 0.2758 - acc: 0.8759 - val_loss: 0.3193 - val_acc: 0.8579\n",
      "Epoch 16/20\n",
      "96040/96040 [==============================] - 102s 1ms/step - loss: 0.2723 - acc: 0.8771 - val_loss: 0.3199 - val_acc: 0.8596\n",
      "Epoch 17/20\n",
      "96040/96040 [==============================] - 102s 1ms/step - loss: 0.2663 - acc: 0.8811 - val_loss: 0.3339 - val_acc: 0.8562\n",
      "Epoch 18/20\n",
      "96040/96040 [==============================] - 99s 1ms/step - loss: 0.2626 - acc: 0.8833 - val_loss: 0.3269 - val_acc: 0.8591\n",
      "Epoch 19/20\n",
      "96040/96040 [==============================] - 99s 1ms/step - loss: 0.2594 - acc: 0.8830 - val_loss: 0.3280 - val_acc: 0.8590\n",
      "Epoch 20/20\n",
      "96040/96040 [==============================] - 100s 1ms/step - loss: 0.2552 - acc: 0.8859 - val_loss: 0.3241 - val_acc: 0.8593\n",
      "\n",
      " Training model n°2\n",
      "Train on 96040 samples, validate on 48020 samples\n",
      "Epoch 1/20\n",
      "96040/96040 [==============================] - 101s 1ms/step - loss: 0.4517 - acc: 0.7838 - val_loss: 0.3959 - val_acc: 0.8110\n",
      "Epoch 2/20\n",
      "96040/96040 [==============================] - 99s 1ms/step - loss: 0.3974 - acc: 0.8117 - val_loss: 0.3825 - val_acc: 0.8179\n",
      "Epoch 3/20\n",
      "96040/96040 [==============================] - 99s 1ms/step - loss: 0.3784 - acc: 0.8236 - val_loss: 0.3708 - val_acc: 0.8249\n",
      "Epoch 4/20\n",
      "96040/96040 [==============================] - 100s 1ms/step - loss: 0.3657 - acc: 0.8293 - val_loss: 0.3608 - val_acc: 0.8328\n",
      "Epoch 5/20\n",
      "96040/96040 [==============================] - 101s 1ms/step - loss: 0.3534 - acc: 0.8354 - val_loss: 0.3556 - val_acc: 0.8320\n",
      "Epoch 6/20\n",
      "96040/96040 [==============================] - 101s 1ms/step - loss: 0.3440 - acc: 0.8418 - val_loss: 0.3496 - val_acc: 0.8405\n",
      "Epoch 7/20\n",
      "96040/96040 [==============================] - 99s 1ms/step - loss: 0.3330 - acc: 0.8473 - val_loss: 0.3401 - val_acc: 0.8440\n",
      "Epoch 8/20\n",
      "96040/96040 [==============================] - 99s 1ms/step - loss: 0.3245 - acc: 0.8520 - val_loss: 0.3355 - val_acc: 0.8500\n",
      "Epoch 9/20\n",
      "96040/96040 [==============================] - 99s 1ms/step - loss: 0.3178 - acc: 0.8560 - val_loss: 0.3439 - val_acc: 0.8431\n",
      "Epoch 10/20\n",
      "96040/96040 [==============================] - 99s 1ms/step - loss: 0.3092 - acc: 0.8605 - val_loss: 0.3288 - val_acc: 0.8491\n",
      "Epoch 11/20\n",
      "96040/96040 [==============================] - 99s 1ms/step - loss: 0.3038 - acc: 0.8632 - val_loss: 0.3328 - val_acc: 0.8538\n",
      "Epoch 12/20\n",
      "96040/96040 [==============================] - 98s 1ms/step - loss: 0.2957 - acc: 0.8676 - val_loss: 0.3280 - val_acc: 0.8534\n",
      "Epoch 13/20\n",
      "96040/96040 [==============================] - 98s 1ms/step - loss: 0.2889 - acc: 0.8698 - val_loss: 0.3351 - val_acc: 0.8517\n",
      "Epoch 14/20\n",
      "96040/96040 [==============================] - 98s 1ms/step - loss: 0.2836 - acc: 0.8725 - val_loss: 0.3319 - val_acc: 0.8560\n",
      "Epoch 15/20\n",
      "96040/96040 [==============================] - 105s 1ms/step - loss: 0.2782 - acc: 0.8756 - val_loss: 0.3278 - val_acc: 0.8554\n",
      "Epoch 16/20\n",
      "96040/96040 [==============================] - 138s 1ms/step - loss: 0.2723 - acc: 0.8777 - val_loss: 0.3186 - val_acc: 0.8608\n",
      "Epoch 17/20\n",
      "96040/96040 [==============================] - 106s 1ms/step - loss: 0.2679 - acc: 0.8813 - val_loss: 0.3197 - val_acc: 0.8588\n",
      "Epoch 18/20\n",
      "96040/96040 [==============================] - 107s 1ms/step - loss: 0.2639 - acc: 0.8819 - val_loss: 0.3211 - val_acc: 0.8568\n",
      "Epoch 19/20\n",
      "96040/96040 [==============================] - 108s 1ms/step - loss: 0.2591 - acc: 0.8849 - val_loss: 0.3407 - val_acc: 0.8578\n",
      "Epoch 20/20\n",
      "96040/96040 [==============================] - 108s 1ms/step - loss: 0.2536 - acc: 0.8875 - val_loss: 0.3253 - val_acc: 0.8623\n",
      "\n",
      " Training model n°3\n",
      "Train on 96040 samples, validate on 48020 samples\n",
      "Epoch 1/20\n",
      "96040/96040 [==============================] - 107s 1ms/step - loss: 0.4494 - acc: 0.7864 - val_loss: 0.4047 - val_acc: 0.8065\n",
      "Epoch 2/20\n",
      "96040/96040 [==============================] - 104s 1ms/step - loss: 0.3967 - acc: 0.8131 - val_loss: 0.3988 - val_acc: 0.8143\n",
      "Epoch 3/20\n",
      "96040/96040 [==============================] - 103s 1ms/step - loss: 0.3779 - acc: 0.8223 - val_loss: 0.3719 - val_acc: 0.8262\n",
      "Epoch 4/20\n",
      "96040/96040 [==============================] - 103s 1ms/step - loss: 0.3637 - acc: 0.8292 - val_loss: 0.3592 - val_acc: 0.8319\n",
      "Epoch 5/20\n",
      "96040/96040 [==============================] - 103s 1ms/step - loss: 0.3536 - acc: 0.8351 - val_loss: 0.3547 - val_acc: 0.8360\n",
      "Epoch 6/20\n",
      "96040/96040 [==============================] - 106s 1ms/step - loss: 0.3422 - acc: 0.8415 - val_loss: 0.3447 - val_acc: 0.8401\n",
      "Epoch 7/20\n",
      "96040/96040 [==============================] - 102s 1ms/step - loss: 0.3341 - acc: 0.8449 - val_loss: 0.3424 - val_acc: 0.8384\n",
      "Epoch 8/20\n",
      "96040/96040 [==============================] - 102s 1ms/step - loss: 0.3265 - acc: 0.8503 - val_loss: 0.3342 - val_acc: 0.8444\n",
      "Epoch 9/20\n",
      "96040/96040 [==============================] - 101s 1ms/step - loss: 0.3175 - acc: 0.8555 - val_loss: 0.3318 - val_acc: 0.8455\n",
      "Epoch 10/20\n",
      "96040/96040 [==============================] - 107s 1ms/step - loss: 0.3132 - acc: 0.8562 - val_loss: 0.3270 - val_acc: 0.8525\n",
      "Epoch 11/20\n",
      "96040/96040 [==============================] - 110s 1ms/step - loss: 0.3051 - acc: 0.8610 - val_loss: 0.3280 - val_acc: 0.8516\n",
      "Epoch 12/20\n",
      "96040/96040 [==============================] - 110s 1ms/step - loss: 0.2991 - acc: 0.8633 - val_loss: 0.3297 - val_acc: 0.8500\n",
      "Epoch 13/20\n",
      "96040/96040 [==============================] - 115s 1ms/step - loss: 0.2933 - acc: 0.8654 - val_loss: 0.3306 - val_acc: 0.8538\n",
      "Epoch 14/20\n",
      "96040/96040 [==============================] - 107s 1ms/step - loss: 0.2878 - acc: 0.8700 - val_loss: 0.3267 - val_acc: 0.8520\n",
      "Epoch 15/20\n",
      "96040/96040 [==============================] - 112s 1ms/step - loss: 0.2847 - acc: 0.8722 - val_loss: 0.3254 - val_acc: 0.8554\n",
      "Epoch 16/20\n",
      "96040/96040 [==============================] - 107s 1ms/step - loss: 0.2783 - acc: 0.8748 - val_loss: 0.3341 - val_acc: 0.8481\n",
      "Epoch 17/20\n",
      "96040/96040 [==============================] - 102s 1ms/step - loss: 0.2734 - acc: 0.8764 - val_loss: 0.3303 - val_acc: 0.8514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "96040/96040 [==============================] - 101s 1ms/step - loss: 0.2699 - acc: 0.8786 - val_loss: 0.3210 - val_acc: 0.8587\n",
      "Epoch 19/20\n",
      "96040/96040 [==============================] - 107s 1ms/step - loss: 0.2652 - acc: 0.8813 - val_loss: 0.3240 - val_acc: 0.8539\n",
      "Epoch 20/20\n",
      "96040/96040 [==============================] - 109s 1ms/step - loss: 0.2596 - acc: 0.8829 - val_loss: 0.3322 - val_acc: 0.8597\n",
      "\n",
      "Making predictions...\n",
      "Prediction accuracy: 87.14%\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = prepare_data()\n",
    "\n",
    "models = train_models(X_train, X_test, y_train, y_test, \n",
    "                      bagging_size=BAGGING_SIZE, bagging_ratio=BAGGING_RATIO, \n",
    "                      epochs=NUM_EPOCHS, batch_size=BATCH_SIZE)\n",
    "\n",
    "preds,hard_preds = predict_with_bagging(models,X_test,y_test,soft_voting = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_1.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_2.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_3.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_4.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_5.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_6.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_7.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_8.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_9.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_10.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_11.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_12.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_13.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_14.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_15.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_16.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_17.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_18.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_19.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_20.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_21.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_22.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_23.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_24.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_25.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_26.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_27.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_28.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_29.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_30.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_31.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_32.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_33.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_34.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_35.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_36.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_37.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_38.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_39.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_40.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_41.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_42.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_43.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_44.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_45.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_46.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_47.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_48.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_49.png\n",
      "\n",
      "Making predictions...\n",
      "(608, 608)\n",
      "test_set_images/pred_50.png\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 51):\n",
    "    img = mpimg.imread('test_set_images/test_' + str(i) + '.png')\n",
    "    data = numpy.asarray(img_crop(img, 16, 16,16))\n",
    "    p, pimg = predict_with_bagging(models,data,soft_voting = False)\n",
    "    #print(pimg.shape)\n",
    "    image_filename = 'test_set_images/pred_' + str(i) + '.png'\n",
    "    #predicted_img= label_to_img(img.shape[0], img.shape[1], IMG_PATCH_SIZE, IMG_PATCH_SIZE, p)\n",
    "    print(predicted_img.shape)\n",
    "\n",
    "\n",
    "    Image.fromarray(bw(predicted_img)).save(image_filename)\n",
    "    print(image_filename)\n",
    "    image_filenames.append(image_filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mask_to_submission import *\n",
    "\n",
    "masks_to_submission('submission.csv', *image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import matplotlib.image as mpimg\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "from PIL import Image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image(infilename):\n",
    "    data = mpimg.imread(infilename)\n",
    "    return data\n",
    "\n",
    "def img_float_to_uint8(img):\n",
    "    rimg = img - numpy.min(img)\n",
    "    rimg = (rimg / numpy.max(rimg) * PIXEL_DEPTH).round().astype(numpy.uint8)\n",
    "    return rimg\n",
    "\n",
    "def concatenate_images(img, gt_img):\n",
    "    nChannels = len(gt_img.shape)\n",
    "    w = gt_img.shape[0]\n",
    "    h = gt_img.shape[1]\n",
    "    if nChannels == 3:\n",
    "        cimg = numpy.concatenate((img, gt_img), axis=1)\n",
    "    else:\n",
    "        gt_img_3c = numpy.zeros((w, h, 3), dtype=numpy.uint8)\n",
    "        gt_img8 = img_float_to_uint8(gt_img)          \n",
    "        gt_img_3c[:,:,0] = gt_img8\n",
    "        gt_img_3c[:,:,1] = gt_img8\n",
    "        gt_img_3c[:,:,2] = gt_img8\n",
    "        img8 = img_float_to_uint8(img)\n",
    "        cimg = numpy.concatenate((img8, gt_img_3c), axis=1)\n",
    "    return cimg\n",
    "\n",
    "def extract_labels(filename, num_images):\n",
    "    \"\"\"Extract the labels into a 1-hot matrix [image index, label index].\"\"\"\n",
    "    gt_imgs = []\n",
    "    for i in range(1, num_images+1):\n",
    "        imageid = \"satImage_%.3d\" % i\n",
    "        image_filename = filename + imageid + \".png\"\n",
    "        if os.path.isfile(image_filename):\n",
    "            print ('Loading ' + image_filename)\n",
    "            img = mpimg.imread(image_filename)\n",
    "            gt_imgs.append(img)\n",
    "        else:\n",
    "            print ('File ' + image_filename + ' does not exist')\n",
    "\n",
    "    num_images = len(gt_imgs)\n",
    "    gt_patches = [img_crop(gt_imgs[i], IMG_PATCH_SIZE, IMG_PATCH_SIZE) for i in range(num_images)]\n",
    "    data = numpy.asarray([gt_patches[i][j] for i in range(len(gt_patches)) for j in range(len(gt_patches[i]))])\n",
    "    labels = numpy.asarray([value_to_class(numpy.mean(data[i])) for i in range(len(data))])\n",
    "\n",
    "    # Convert to dense 1-hot representation.\n",
    "    return labels.astype(numpy.float32)\n",
    "\n",
    "def img_crop(im, w, h):\n",
    "    list_patches = []\n",
    "    imgwidth = im.shape[0]\n",
    "    imgheight = im.shape[1]\n",
    "    is_2d = len(im.shape) < 3\n",
    "    for i in range(0,imgheight,h):\n",
    "        for j in range(0,imgwidth,w):\n",
    "            if is_2d:\n",
    "                im_patch = im[j:j+w, i:i+h]\n",
    "            else:\n",
    "                im_patch = im[j:j+w, i:i+h, :]\n",
    "            list_patches.append(im_patch)\n",
    "    return list_patches\n",
    "\n",
    "foreground_threshold = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "\n",
    "def value_to_class(v):\n",
    "    foreground_threshold = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "    df = numpy.sum(v)\n",
    "    if df > foreground_threshold:\n",
    "        return [0, 1]\n",
    "    else:\n",
    "        return [1, 0]\n",
    "        \n",
    "def extract_data(filename, num_images):\n",
    "    \"\"\"Extract the images into a 4D tensor [image index, y, x, channels].\n",
    "    Values are rescaled from [0, 255] down to [-0.5, 0.5].\n",
    "    \"\"\"\n",
    "    imgs = []\n",
    "    for i in range(1, num_images+1):\n",
    "        imageid = \"satImage_%.3d\" % i\n",
    "        image_filename = filename + imageid + \".png\"\n",
    "        if os.path.isfile(image_filename):\n",
    "            print ('Loading ' + image_filename)\n",
    "            img = mpimg.imread(image_filename)\n",
    "            imgs.append(img)\n",
    "        else:\n",
    "            print ('File ' + image_filename + ' does not exist')\n",
    "\n",
    "    num_images = len(imgs)\n",
    "    IMG_WIDTH = imgs[0].shape[0]\n",
    "    IMG_HEIGHT = imgs[0].shape[1]\n",
    "    N_PATCHES_PER_IMAGE = (IMG_WIDTH/IMG_PATCH_SIZE)*(IMG_HEIGHT/IMG_PATCH_SIZE)\n",
    "\n",
    "    img_patches = [img_crop(imgs[i], IMG_PATCH_SIZE, IMG_PATCH_SIZE) for i in range(num_images)]\n",
    "    data = [img_patches[i][j] for i in range(len(img_patches)) for j in range(len(img_patches[i]))]\n",
    "\n",
    "    return numpy.asarray(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "NUM_CHANNELS = 3 # RGB images\n",
    "PIXEL_DEPTH = 255\n",
    "NUM_LABELS = 2\n",
    "TRAINING_SIZE = 20\n",
    "VALIDATION_SIZE = 5  # Size of the validation set.\n",
    "SEED = 66478  # Set to None for random seed.\n",
    "BATCH_SIZE = 16 # 64\n",
    "NUM_EPOCHS = 5\n",
    "RESTORE_MODEL = False # If True, restore existing model instead of training a new one\n",
    "RECORDING_STEP = 1000\n",
    "IMG_PATCH_SIZE = 16\n",
    "\n",
    "root_dir = \"training/\"\n",
    "image_dir = root_dir + \"images/\"\n",
    "gt_dir = root_dir + \"groundtruth/\"\n",
    "\n",
    "train_data = extract_data(image_dir, TRAINING_SIZE)\n",
    "train_labels = extract_labels(gt_dir, TRAINING_SIZE)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import Input, merge, Conv2D, MaxPooling2D, UpSampling2D, Dropout, Cropping2D, concatenate, Dense, Flatten\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "\n",
    "\n",
    "input_x = Input(shape=(16, 16,3), name='input_x') \n",
    "conv1 = Conv2D(64, (3,3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(input_x)\n",
    "print(\"conv1 shape:\",conv1.shape)\n",
    "conv1 = Conv2D(64, (3,3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "print(\"conv1 shape:\",conv1.shape)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "print(\"pool1 shape:\",pool1.shape)\n",
    "\n",
    "conv2 = Conv2D(128, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "print(\"conv2 shape:\",conv2.shape)\n",
    "conv2 = Conv2D(128, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "print(\"conv2 shape:\",conv2.shape)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "print(\"pool2 shape:\",pool2.shape)\n",
    "\n",
    "conv3 = Conv2D(256, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "print(\"conv3 shape:\",conv3.shape)\n",
    "conv3 = Conv2D(256, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "print(\"conv3 shape:\",conv3.shape)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "print(\"pool3 shape:\",pool3.shape)\n",
    "\n",
    "conv4 = Conv2D(512, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "conv4 = Conv2D(512, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "drop4 = Dropout(0.5)(conv4)\n",
    "pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "conv5 = Conv2D(1024, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "conv5 = Conv2D(1024, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "#merge6 = merge([drop4,up6], mode = 'concat', concat_axis = 3)\n",
    "merge6 = concatenate([drop4,up6],axis = 3)\n",
    "conv6 = Conv2D(512, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "conv6 = Conv2D(512, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "#merge7 = merge([conv3,up7], mode = 'concat', concat_axis = 3)\n",
    "merge7 = concatenate([conv3,up7], axis = 3)\n",
    "conv7 = Conv2D(256, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "conv7 = Conv2D(256, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "#merge8 = merge([conv2,up8], mode = 'concat', concat_axis = 3)\n",
    "merge8 = concatenate([conv2,up8], axis = 3)\n",
    "conv8 = Conv2D(128, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "conv8 = Conv2D(128, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "#merge9 = merge([conv1,up9], mode = 'concat', concat_axis = 3)\n",
    "merge9 = concatenate([conv1,up9], axis = 3)\n",
    "conv9 = Conv2D(64, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "conv9 = Conv2D(64, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "conv9 = Conv2D(2, (3, 3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "#conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "#print(conv10.shape)\n",
    "\n",
    "\n",
    "res = Dense(2, activation='sigmoid')(Flatten()(conv9))\n",
    "\n",
    "print(res.shape)\n",
    "model = Model(inputs = input_x, outputs = res) #conv10\n",
    "\n",
    "model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=16, epochs=10, verbose=1,validation_split=0.2, shuffle=True)\n",
    "#model.fit(X_train, y_train, batch_size=16, epochs=10, verbose=1,validation_data=(X_test, y_test), shuffle=True)\n",
    "#print('predict test data')\n",
    "#y_test = model.predict(X_test, batch_size=1, verbose=1)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1444, 2)\n",
      "test_set_images/pred_1.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_2.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_3.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_4.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_5.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_6.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_7.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_8.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_9.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_10.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_11.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_12.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_13.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_14.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_15.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_16.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_17.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_18.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_19.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_20.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_21.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_22.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_23.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_24.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_25.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_26.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_27.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_28.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_29.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_30.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_31.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_32.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_33.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_34.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_35.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_36.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_37.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_38.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_39.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_40.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_41.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_42.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_43.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_44.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_45.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_46.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_47.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_48.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_49.png\n",
      "(1444, 2)\n",
      "test_set_images/pred_50.png\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test_set_images/test_51.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-2ef911e02611>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;34m'test_set_images/test_'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mtest_data_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'test_set_images/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mpimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_prediction_with_groundtruth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0mimage_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'test_set_images/pred_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-104-2ef911e02611>\u001b[0m in \u001b[0;36mget_prediction_with_groundtruth\u001b[0;34m(filename, image_idx)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mimageid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"test_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mimage_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimageid\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".png\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mimg_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/besmaelketroussi/anaconda/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1295\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1298\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test_set_images/test_51.png'"
     ]
    }
   ],
   "source": [
    "def label_to_img(imgwidth, imgheight, w, h, labels):\n",
    "    array_labels = numpy.zeros([imgwidth, imgheight])\n",
    "    idx = 0\n",
    "    for i in range(0,imgheight,h):\n",
    "        for j in range(0,imgwidth,w):\n",
    "            if labels[idx][0] > 0.5:\n",
    "                l = 0\n",
    "            else:\n",
    "                l = 1\n",
    "            array_labels[j:j+w, i:i+h] = l\n",
    "            idx = idx + 1\n",
    "    return array_labels\n",
    "\n",
    "def concatenate_images(img, gt_img):\n",
    "    nChannels = len(gt_img.shape)\n",
    "    w = gt_img.shape[0]\n",
    "    h = gt_img.shape[1]\n",
    "    if nChannels == 3:\n",
    "        cimg = numpy.concatenate((img, gt_img), axis=1)\n",
    "    else:\n",
    "        gt_img_3c = numpy.zeros((w, h, 3), dtype=numpy.uint8)\n",
    "        gt_img8 = img_float_to_uint8(gt_img)          \n",
    "        gt_img_3c[:,:,0] = gt_img8\n",
    "        gt_img_3c[:,:,1] = gt_img8\n",
    "        gt_img_3c[:,:,2] = gt_img8\n",
    "        img8 = img_float_to_uint8(img)\n",
    "        cimg = numpy.concatenate((img8, gt_img_3c), axis=1)\n",
    "    return cimg\n",
    "\n",
    "def bw(gt_img):\n",
    "    nChannels = len(gt_img.shape)\n",
    "    w = gt_img.shape[0]\n",
    "    h = gt_img.shape[1]\n",
    "    if nChannels == 3:\n",
    "        cimg = gt_img #np.concatenate((img, gt_img), axis=1)\n",
    "    else:\n",
    "        gt_img_3c = np.zeros((w, h, 3), dtype=np.uint8)\n",
    "        gt_img8 = img_float_to_uint8(gt_img)          \n",
    "        gt_img_3c[:,:,0] = gt_img8\n",
    "        gt_img_3c[:,:,1] = gt_img8\n",
    "        gt_img_3c[:,:,2] = gt_img8\n",
    "        cimg = gt_img_3c\n",
    "    return cimg\n",
    "\n",
    "    # Get prediction for given input image \n",
    "def get_prediction(img):\n",
    "    data = numpy.asarray(img_crop(img, IMG_PATCH_SIZE, IMG_PATCH_SIZE))\n",
    "    output_prediction = models[1].predict(data)\n",
    "\n",
    "    print(output_prediction.shape)\n",
    "    img_prediction = label_to_img(img.shape[0], img.shape[1], IMG_PATCH_SIZE, IMG_PATCH_SIZE, output_prediction)\n",
    "\n",
    "    return img_prediction\n",
    "\n",
    "    # Get a concatenation of the prediction and groundtruth for given input file\n",
    "def get_prediction_with_groundtruth(filename, image_idx):\n",
    "    \n",
    "    imageid = \"test_\" + str(image_idx)\n",
    "    image_filename = filename + imageid + \".png\"\n",
    "    img = mpimg.imread(image_filename)\n",
    "    \n",
    "    img_prediction = get_prediction(img)\n",
    "    #cimg = concatenate_images(img, img_prediction)\n",
    "    #cimg = Image.fromarray(bw(img_prediction))\n",
    "\n",
    "    #return cimg\n",
    "    return img_prediction\n",
    "\n",
    "submission_filename = 'submission.csv'\n",
    "image_filenames = []\n",
    "\n",
    "for i in range(1, TRAINING_SIZE+1):\n",
    "    'test_set_images/test_'\n",
    "    test_data_filename = 'test_set_images/'\n",
    "    pimg = get_prediction_with_groundtruth(test_data_filename, i)\n",
    "    image_filename = 'test_set_images/pred_' + str(i) + '.png'\n",
    "    Image.fromarray(bw(pimg)).save(image_filename)\n",
    "    print(image_filename)\n",
    "    image_filenames.append(image_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mask_to_submission import *\n",
    "\n",
    "masks_to_submission('submission.csv', *image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
