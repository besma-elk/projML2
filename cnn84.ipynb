{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 84.43% , 0.82337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/besmaelketroussi/anaconda/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import matplotlib.image as mpimg\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "from PIL import Image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image(infilename):\n",
    "    data = mpimg.imread(infilename)\n",
    "    return data\n",
    "\n",
    "def img_float_to_uint8(img):\n",
    "    rimg = img - numpy.min(img)\n",
    "    rimg = (rimg / numpy.max(rimg) * PIXEL_DEPTH).round().astype(numpy.uint8)\n",
    "    return rimg\n",
    "\n",
    "def concatenate_images(img, gt_img):\n",
    "    nChannels = len(gt_img.shape)\n",
    "    w = gt_img.shape[0]\n",
    "    h = gt_img.shape[1]\n",
    "    if nChannels == 3:\n",
    "        cimg = numpy.concatenate((img, gt_img), axis=1)\n",
    "    else:\n",
    "        gt_img_3c = numpy.zeros((w, h, 3), dtype=numpy.uint8)\n",
    "        gt_img8 = img_float_to_uint8(gt_img)          \n",
    "        gt_img_3c[:,:,0] = gt_img8\n",
    "        gt_img_3c[:,:,1] = gt_img8\n",
    "        gt_img_3c[:,:,2] = gt_img8\n",
    "        img8 = img_float_to_uint8(img)\n",
    "        cimg = numpy.concatenate((img8, gt_img_3c), axis=1)\n",
    "    return cimg\n",
    "\n",
    "def extract_labels(filename, num_images):\n",
    "    \"\"\"Extract the labels into a 1-hot matrix [image index, label index].\"\"\"\n",
    "    gt_imgs = []\n",
    "    for i in range(1, num_images+1):\n",
    "        imageid = \"satImage_%.3d\" % i\n",
    "        image_filename = filename + imageid + \".png\"\n",
    "        if os.path.isfile(image_filename):\n",
    "            print ('Loading ' + image_filename)\n",
    "            img = mpimg.imread(image_filename)\n",
    "            gt_imgs.append(img)\n",
    "        else:\n",
    "            print ('File ' + image_filename + ' does not exist')\n",
    "\n",
    "    num_images = len(gt_imgs)\n",
    "    gt_patches = [img_crop(gt_imgs[i], IMG_PATCH_SIZE, IMG_PATCH_SIZE) for i in range(num_images)]\n",
    "    data = numpy.asarray([gt_patches[i][j] for i in range(len(gt_patches)) for j in range(len(gt_patches[i]))])\n",
    "    labels = numpy.asarray([value_to_class(numpy.mean(data[i])) for i in range(len(data))])\n",
    "\n",
    "    # Convert to dense 1-hot representation.\n",
    "    return labels.astype(numpy.float32)\n",
    "\n",
    "def img_crop(im, w, h):\n",
    "    list_patches = []\n",
    "    imgwidth = im.shape[0]\n",
    "    imgheight = im.shape[1]\n",
    "    is_2d = len(im.shape) < 3\n",
    "    for i in range(0,imgheight,h):\n",
    "        for j in range(0,imgwidth,w):\n",
    "            if is_2d:\n",
    "                im_patch = im[j:j+w, i:i+h]\n",
    "            else:\n",
    "                im_patch = im[j:j+w, i:i+h, :]\n",
    "            list_patches.append(im_patch)\n",
    "    return list_patches\n",
    "\n",
    "foreground_threshold = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "\n",
    "def value_to_class(v):\n",
    "    foreground_threshold = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "    df = numpy.sum(v)\n",
    "    if df > foreground_threshold:\n",
    "        return [0, 1]\n",
    "    else:\n",
    "        return [1, 0]\n",
    "        \n",
    "def extract_data(filename, num_images):\n",
    "    \"\"\"Extract the images into a 4D tensor [image index, y, x, channels].\n",
    "    Values are rescaled from [0, 255] down to [-0.5, 0.5].\n",
    "    \"\"\"\n",
    "    imgs = []\n",
    "    for i in range(1, num_images+1):\n",
    "        imageid = \"satImage_%.3d\" % i\n",
    "        image_filename = filename + imageid + \".png\"\n",
    "        if os.path.isfile(image_filename):\n",
    "            print ('Loading ' + image_filename)\n",
    "            img = mpimg.imread(image_filename)\n",
    "            imgs.append(img)\n",
    "        else:\n",
    "            print ('File ' + image_filename + ' does not exist')\n",
    "\n",
    "    num_images = len(imgs)\n",
    "    IMG_WIDTH = imgs[0].shape[0]\n",
    "    IMG_HEIGHT = imgs[0].shape[1]\n",
    "    N_PATCHES_PER_IMAGE = (IMG_WIDTH/IMG_PATCH_SIZE)*(IMG_HEIGHT/IMG_PATCH_SIZE)\n",
    "\n",
    "    img_patches = [img_crop(imgs[i], IMG_PATCH_SIZE, IMG_PATCH_SIZE) for i in range(num_images)]\n",
    "    data = [img_patches[i][j] for i in range(len(img_patches)) for j in range(len(img_patches[i]))]\n",
    "\n",
    "    return numpy.asarray(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training/images/satImage_001.png\n",
      "Loading training/images/satImage_002.png\n",
      "Loading training/images/satImage_003.png\n",
      "Loading training/images/satImage_004.png\n",
      "Loading training/images/satImage_005.png\n",
      "Loading training/images/satImage_006.png\n",
      "Loading training/images/satImage_007.png\n",
      "Loading training/images/satImage_008.png\n",
      "Loading training/images/satImage_009.png\n",
      "Loading training/images/satImage_010.png\n",
      "Loading training/images/satImage_011.png\n",
      "Loading training/images/satImage_012.png\n",
      "Loading training/images/satImage_013.png\n",
      "Loading training/images/satImage_014.png\n",
      "Loading training/images/satImage_015.png\n",
      "Loading training/images/satImage_016.png\n",
      "Loading training/images/satImage_017.png\n",
      "Loading training/images/satImage_018.png\n",
      "Loading training/images/satImage_019.png\n",
      "Loading training/images/satImage_020.png\n",
      "Loading training/images/satImage_021.png\n",
      "Loading training/images/satImage_022.png\n",
      "Loading training/images/satImage_023.png\n",
      "Loading training/images/satImage_024.png\n",
      "Loading training/images/satImage_025.png\n",
      "Loading training/images/satImage_026.png\n",
      "Loading training/images/satImage_027.png\n",
      "Loading training/images/satImage_028.png\n",
      "Loading training/images/satImage_029.png\n",
      "Loading training/images/satImage_030.png\n",
      "Loading training/images/satImage_031.png\n",
      "Loading training/images/satImage_032.png\n",
      "Loading training/images/satImage_033.png\n",
      "Loading training/images/satImage_034.png\n",
      "Loading training/images/satImage_035.png\n",
      "Loading training/images/satImage_036.png\n",
      "Loading training/images/satImage_037.png\n",
      "Loading training/images/satImage_038.png\n",
      "Loading training/images/satImage_039.png\n",
      "Loading training/images/satImage_040.png\n",
      "Loading training/images/satImage_041.png\n",
      "Loading training/images/satImage_042.png\n",
      "Loading training/images/satImage_043.png\n",
      "Loading training/images/satImage_044.png\n",
      "Loading training/images/satImage_045.png\n",
      "Loading training/images/satImage_046.png\n",
      "Loading training/images/satImage_047.png\n",
      "Loading training/images/satImage_048.png\n",
      "Loading training/images/satImage_049.png\n",
      "Loading training/images/satImage_050.png\n",
      "Loading training/images/satImage_051.png\n",
      "Loading training/images/satImage_052.png\n",
      "Loading training/images/satImage_053.png\n",
      "Loading training/images/satImage_054.png\n",
      "Loading training/images/satImage_055.png\n",
      "Loading training/images/satImage_056.png\n",
      "Loading training/images/satImage_057.png\n",
      "Loading training/images/satImage_058.png\n",
      "Loading training/images/satImage_059.png\n",
      "Loading training/images/satImage_060.png\n",
      "Loading training/images/satImage_061.png\n",
      "Loading training/images/satImage_062.png\n",
      "Loading training/images/satImage_063.png\n",
      "Loading training/images/satImage_064.png\n",
      "Loading training/images/satImage_065.png\n",
      "Loading training/images/satImage_066.png\n",
      "Loading training/images/satImage_067.png\n",
      "Loading training/images/satImage_068.png\n",
      "Loading training/images/satImage_069.png\n",
      "Loading training/images/satImage_070.png\n",
      "Loading training/images/satImage_071.png\n",
      "Loading training/images/satImage_072.png\n",
      "Loading training/images/satImage_073.png\n",
      "Loading training/images/satImage_074.png\n",
      "Loading training/images/satImage_075.png\n",
      "Loading training/images/satImage_076.png\n",
      "Loading training/images/satImage_077.png\n",
      "Loading training/images/satImage_078.png\n",
      "Loading training/images/satImage_079.png\n",
      "Loading training/images/satImage_080.png\n",
      "Loading training/images/satImage_081.png\n",
      "Loading training/images/satImage_082.png\n",
      "Loading training/images/satImage_083.png\n",
      "Loading training/images/satImage_084.png\n",
      "Loading training/images/satImage_085.png\n",
      "Loading training/images/satImage_086.png\n",
      "Loading training/images/satImage_087.png\n",
      "Loading training/images/satImage_088.png\n",
      "Loading training/images/satImage_089.png\n",
      "Loading training/images/satImage_090.png\n",
      "Loading training/images/satImage_091.png\n",
      "Loading training/images/satImage_092.png\n",
      "Loading training/images/satImage_093.png\n",
      "Loading training/images/satImage_094.png\n",
      "Loading training/images/satImage_095.png\n",
      "Loading training/images/satImage_096.png\n",
      "Loading training/images/satImage_097.png\n",
      "Loading training/images/satImage_098.png\n",
      "Loading training/images/satImage_099.png\n",
      "Loading training/images/satImage_100.png\n",
      "Loading training/groundtruth/satImage_001.png\n",
      "Loading training/groundtruth/satImage_002.png\n",
      "Loading training/groundtruth/satImage_003.png\n",
      "Loading training/groundtruth/satImage_004.png\n",
      "Loading training/groundtruth/satImage_005.png\n",
      "Loading training/groundtruth/satImage_006.png\n",
      "Loading training/groundtruth/satImage_007.png\n",
      "Loading training/groundtruth/satImage_008.png\n",
      "Loading training/groundtruth/satImage_009.png\n",
      "Loading training/groundtruth/satImage_010.png\n",
      "Loading training/groundtruth/satImage_011.png\n",
      "Loading training/groundtruth/satImage_012.png\n",
      "Loading training/groundtruth/satImage_013.png\n",
      "Loading training/groundtruth/satImage_014.png\n",
      "Loading training/groundtruth/satImage_015.png\n",
      "Loading training/groundtruth/satImage_016.png\n",
      "Loading training/groundtruth/satImage_017.png\n",
      "Loading training/groundtruth/satImage_018.png\n",
      "Loading training/groundtruth/satImage_019.png\n",
      "Loading training/groundtruth/satImage_020.png\n",
      "Loading training/groundtruth/satImage_021.png\n",
      "Loading training/groundtruth/satImage_022.png\n",
      "Loading training/groundtruth/satImage_023.png\n",
      "Loading training/groundtruth/satImage_024.png\n",
      "Loading training/groundtruth/satImage_025.png\n",
      "Loading training/groundtruth/satImage_026.png\n",
      "Loading training/groundtruth/satImage_027.png\n",
      "Loading training/groundtruth/satImage_028.png\n",
      "Loading training/groundtruth/satImage_029.png\n",
      "Loading training/groundtruth/satImage_030.png\n",
      "Loading training/groundtruth/satImage_031.png\n",
      "Loading training/groundtruth/satImage_032.png\n",
      "Loading training/groundtruth/satImage_033.png\n",
      "Loading training/groundtruth/satImage_034.png\n",
      "Loading training/groundtruth/satImage_035.png\n",
      "Loading training/groundtruth/satImage_036.png\n",
      "Loading training/groundtruth/satImage_037.png\n",
      "Loading training/groundtruth/satImage_038.png\n",
      "Loading training/groundtruth/satImage_039.png\n",
      "Loading training/groundtruth/satImage_040.png\n",
      "Loading training/groundtruth/satImage_041.png\n",
      "Loading training/groundtruth/satImage_042.png\n",
      "Loading training/groundtruth/satImage_043.png\n",
      "Loading training/groundtruth/satImage_044.png\n",
      "Loading training/groundtruth/satImage_045.png\n",
      "Loading training/groundtruth/satImage_046.png\n",
      "Loading training/groundtruth/satImage_047.png\n",
      "Loading training/groundtruth/satImage_048.png\n",
      "Loading training/groundtruth/satImage_049.png\n",
      "Loading training/groundtruth/satImage_050.png\n",
      "Loading training/groundtruth/satImage_051.png\n",
      "Loading training/groundtruth/satImage_052.png\n",
      "Loading training/groundtruth/satImage_053.png\n",
      "Loading training/groundtruth/satImage_054.png\n",
      "Loading training/groundtruth/satImage_055.png\n",
      "Loading training/groundtruth/satImage_056.png\n",
      "Loading training/groundtruth/satImage_057.png\n",
      "Loading training/groundtruth/satImage_058.png\n",
      "Loading training/groundtruth/satImage_059.png\n",
      "Loading training/groundtruth/satImage_060.png\n",
      "Loading training/groundtruth/satImage_061.png\n",
      "Loading training/groundtruth/satImage_062.png\n",
      "Loading training/groundtruth/satImage_063.png\n",
      "Loading training/groundtruth/satImage_064.png\n",
      "Loading training/groundtruth/satImage_065.png\n",
      "Loading training/groundtruth/satImage_066.png\n",
      "Loading training/groundtruth/satImage_067.png\n",
      "Loading training/groundtruth/satImage_068.png\n",
      "Loading training/groundtruth/satImage_069.png\n",
      "Loading training/groundtruth/satImage_070.png\n",
      "Loading training/groundtruth/satImage_071.png\n",
      "Loading training/groundtruth/satImage_072.png\n",
      "Loading training/groundtruth/satImage_073.png\n",
      "Loading training/groundtruth/satImage_074.png\n",
      "Loading training/groundtruth/satImage_075.png\n",
      "Loading training/groundtruth/satImage_076.png\n",
      "Loading training/groundtruth/satImage_077.png\n",
      "Loading training/groundtruth/satImage_078.png\n",
      "Loading training/groundtruth/satImage_079.png\n",
      "Loading training/groundtruth/satImage_080.png\n",
      "Loading training/groundtruth/satImage_081.png\n",
      "Loading training/groundtruth/satImage_082.png\n",
      "Loading training/groundtruth/satImage_083.png\n",
      "Loading training/groundtruth/satImage_084.png\n",
      "Loading training/groundtruth/satImage_085.png\n",
      "Loading training/groundtruth/satImage_086.png\n",
      "Loading training/groundtruth/satImage_087.png\n",
      "Loading training/groundtruth/satImage_088.png\n",
      "Loading training/groundtruth/satImage_089.png\n",
      "Loading training/groundtruth/satImage_090.png\n",
      "Loading training/groundtruth/satImage_091.png\n",
      "Loading training/groundtruth/satImage_092.png\n",
      "Loading training/groundtruth/satImage_093.png\n",
      "Loading training/groundtruth/satImage_094.png\n",
      "Loading training/groundtruth/satImage_095.png\n",
      "Loading training/groundtruth/satImage_096.png\n",
      "Loading training/groundtruth/satImage_097.png\n",
      "Loading training/groundtruth/satImage_098.png\n",
      "Loading training/groundtruth/satImage_099.png\n",
      "Loading training/groundtruth/satImage_100.png\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "NUM_CHANNELS = 3 # RGB images\n",
    "PIXEL_DEPTH = 255\n",
    "NUM_LABELS = 2\n",
    "TRAINING_SIZE = 100\n",
    "VALIDATION_SIZE = 5  # Size of the validation set.\n",
    "SEED = 66478  # Set to None for random seed.\n",
    "BATCH_SIZE = 128 # 64\n",
    "NUM_EPOCHS = 150\n",
    "RESTORE_MODEL = False # If True, restore existing model instead of training a new one\n",
    "RECORDING_STEP = 1000\n",
    "\n",
    "# Set image patch size in pixels\n",
    "# IMG_PATCH_SIZE should be a multiple of 4\n",
    "# image size should be an integer multiple of this number!\n",
    "IMG_PATCH_SIZE = 16\n",
    "\n",
    "root_dir = \"training/\"\n",
    "image_dir = root_dir + \"images/\"\n",
    "gt_dir = root_dir + \"groundtruth/\"\n",
    "\n",
    "train_data = extract_data(image_dir, TRAINING_SIZE)\n",
    "train_labels = extract_labels(gt_dir, TRAINING_SIZE)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 94,274\n",
      "Trainable params: 94,274\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(16, 16,3), padding='same', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(32, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "#model.add(Activation('sigmoid'))\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "epochs = NUM_EPOCHS\n",
    "lrate = 0.01\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=1e-6, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/150\n",
      "50000/50000 [==============================] - 45s 893us/step - loss: 0.5288 - acc: 0.7414 - val_loss: 0.5048 - val_acc: 0.7373\n",
      "Epoch 2/150\n",
      "50000/50000 [==============================] - 39s 783us/step - loss: 0.4946 - acc: 0.7518 - val_loss: 0.4991 - val_acc: 0.7586\n",
      "Epoch 3/150\n",
      "50000/50000 [==============================] - 39s 782us/step - loss: 0.4623 - acc: 0.7728 - val_loss: 0.4751 - val_acc: 0.7574\n",
      "Epoch 4/150\n",
      "50000/50000 [==============================] - 39s 783us/step - loss: 0.4296 - acc: 0.7904 - val_loss: 0.3978 - val_acc: 0.8114\n",
      "Epoch 5/150\n",
      "50000/50000 [==============================] - 39s 783us/step - loss: 0.4170 - acc: 0.7982 - val_loss: 0.4216 - val_acc: 0.7961\n",
      "Epoch 6/150\n",
      "50000/50000 [==============================] - 39s 789us/step - loss: 0.4018 - acc: 0.8064 - val_loss: 0.3925 - val_acc: 0.8121\n",
      "Epoch 7/150\n",
      "50000/50000 [==============================] - 39s 785us/step - loss: 0.3916 - acc: 0.8154 - val_loss: 0.3878 - val_acc: 0.8209\n",
      "Epoch 8/150\n",
      "50000/50000 [==============================] - 39s 782us/step - loss: 0.3822 - acc: 0.8162 - val_loss: 0.3967 - val_acc: 0.8044\n",
      "Epoch 9/150\n",
      "50000/50000 [==============================] - 42s 837us/step - loss: 0.3774 - acc: 0.8216 - val_loss: 0.3710 - val_acc: 0.8214\n",
      "Epoch 10/150\n",
      "50000/50000 [==============================] - 41s 814us/step - loss: 0.3707 - acc: 0.8233 - val_loss: 0.3681 - val_acc: 0.8263\n",
      "Epoch 11/150\n",
      "50000/50000 [==============================] - 39s 789us/step - loss: 0.3649 - acc: 0.8272 - val_loss: 0.3672 - val_acc: 0.8330\n",
      "Epoch 12/150\n",
      "50000/50000 [==============================] - 40s 790us/step - loss: 0.3570 - acc: 0.8328 - val_loss: 0.3633 - val_acc: 0.8278\n",
      "Epoch 13/150\n",
      "50000/50000 [==============================] - 39s 789us/step - loss: 0.3525 - acc: 0.8365 - val_loss: 0.3599 - val_acc: 0.8308\n",
      "Epoch 14/150\n",
      "50000/50000 [==============================] - 39s 789us/step - loss: 0.3469 - acc: 0.8398 - val_loss: 0.3616 - val_acc: 0.8323\n",
      "Epoch 15/150\n",
      "50000/50000 [==============================] - 40s 796us/step - loss: 0.3437 - acc: 0.8396 - val_loss: 0.3529 - val_acc: 0.8385\n",
      "Epoch 16/150\n",
      "50000/50000 [==============================] - 40s 793us/step - loss: 0.3390 - acc: 0.8424 - val_loss: 0.3460 - val_acc: 0.8387\n",
      "Epoch 17/150\n",
      "50000/50000 [==============================] - 40s 791us/step - loss: 0.3329 - acc: 0.8449 - val_loss: 0.3427 - val_acc: 0.8433\n",
      "Epoch 18/150\n",
      "50000/50000 [==============================] - 40s 800us/step - loss: 0.3273 - acc: 0.8468 - val_loss: 0.3648 - val_acc: 0.8338\n",
      "Epoch 19/150\n",
      "50000/50000 [==============================] - 39s 789us/step - loss: 0.3257 - acc: 0.8490 - val_loss: 0.3459 - val_acc: 0.8409\n",
      "Epoch 20/150\n",
      "50000/50000 [==============================] - 44s 874us/step - loss: 0.3203 - acc: 0.8497 - val_loss: 0.3569 - val_acc: 0.8340\n",
      "Epoch 21/150\n",
      "50000/50000 [==============================] - 40s 803us/step - loss: 0.3162 - acc: 0.8541 - val_loss: 0.3702 - val_acc: 0.8271\n",
      "Epoch 22/150\n",
      "50000/50000 [==============================] - 39s 786us/step - loss: 0.3135 - acc: 0.8547 - val_loss: 0.3382 - val_acc: 0.8458\n",
      "Epoch 23/150\n",
      "50000/50000 [==============================] - 39s 785us/step - loss: 0.3088 - acc: 0.8570 - val_loss: 0.3372 - val_acc: 0.8459\n",
      "Epoch 24/150\n",
      "50000/50000 [==============================] - 39s 789us/step - loss: 0.3046 - acc: 0.8598 - val_loss: 0.3656 - val_acc: 0.8310\n",
      "Epoch 25/150\n",
      "50000/50000 [==============================] - 39s 788us/step - loss: 0.3021 - acc: 0.8607 - val_loss: 0.3426 - val_acc: 0.8471\n",
      "Epoch 26/150\n",
      "50000/50000 [==============================] - 39s 788us/step - loss: 0.2984 - acc: 0.8609 - val_loss: 0.3598 - val_acc: 0.8414\n",
      "Epoch 27/150\n",
      "50000/50000 [==============================] - 39s 790us/step - loss: 0.2933 - acc: 0.8647 - val_loss: 0.3671 - val_acc: 0.8382\n",
      "Epoch 28/150\n",
      "50000/50000 [==============================] - 40s 794us/step - loss: 0.2931 - acc: 0.8657 - val_loss: 0.3465 - val_acc: 0.8402\n",
      "Epoch 29/150\n",
      "50000/50000 [==============================] - 39s 789us/step - loss: 0.2910 - acc: 0.8674 - val_loss: 0.3451 - val_acc: 0.8506\n",
      "Epoch 30/150\n",
      "50000/50000 [==============================] - 40s 791us/step - loss: 0.2857 - acc: 0.8700 - val_loss: 0.3425 - val_acc: 0.8442\n",
      "Epoch 31/150\n",
      "50000/50000 [==============================] - 40s 790us/step - loss: 0.2840 - acc: 0.8692 - val_loss: 0.3497 - val_acc: 0.8433\n",
      "Epoch 32/150\n",
      "50000/50000 [==============================] - 39s 789us/step - loss: 0.2807 - acc: 0.8718 - val_loss: 0.3475 - val_acc: 0.8500\n",
      "Epoch 33/150\n",
      "50000/50000 [==============================] - 39s 789us/step - loss: 0.2784 - acc: 0.8739 - val_loss: 0.3627 - val_acc: 0.8418\n",
      "Epoch 34/150\n",
      "50000/50000 [==============================] - 40s 790us/step - loss: 0.2758 - acc: 0.8751 - val_loss: 0.3497 - val_acc: 0.8459\n",
      "Epoch 35/150\n",
      "50000/50000 [==============================] - 39s 789us/step - loss: 0.2713 - acc: 0.8773 - val_loss: 0.3474 - val_acc: 0.8491\n",
      "Epoch 36/150\n",
      "50000/50000 [==============================] - 39s 783us/step - loss: 0.2673 - acc: 0.8782 - val_loss: 0.3597 - val_acc: 0.8494\n",
      "Epoch 37/150\n",
      "50000/50000 [==============================] - 39s 779us/step - loss: 0.2669 - acc: 0.8786 - val_loss: 0.3547 - val_acc: 0.8498\n",
      "Epoch 38/150\n",
      "50000/50000 [==============================] - 39s 779us/step - loss: 0.2634 - acc: 0.8797 - val_loss: 0.3597 - val_acc: 0.8488\n",
      "Epoch 39/150\n",
      "50000/50000 [==============================] - 39s 779us/step - loss: 0.2629 - acc: 0.8805 - val_loss: 0.3554 - val_acc: 0.8477\n",
      "Epoch 40/150\n",
      "50000/50000 [==============================] - 39s 779us/step - loss: 0.2604 - acc: 0.8819 - val_loss: 0.3613 - val_acc: 0.8398\n",
      "Epoch 41/150\n",
      "50000/50000 [==============================] - 39s 780us/step - loss: 0.2592 - acc: 0.8824 - val_loss: 0.3619 - val_acc: 0.8437\n",
      "Epoch 42/150\n",
      "50000/50000 [==============================] - 39s 781us/step - loss: 0.2551 - acc: 0.8845 - val_loss: 0.3565 - val_acc: 0.8430\n",
      "Epoch 43/150\n",
      "50000/50000 [==============================] - 39s 780us/step - loss: 0.2534 - acc: 0.8837 - val_loss: 0.3505 - val_acc: 0.8522\n",
      "Epoch 44/150\n",
      "50000/50000 [==============================] - 39s 781us/step - loss: 0.2500 - acc: 0.8850 - val_loss: 0.3614 - val_acc: 0.8398\n",
      "Epoch 45/150\n",
      "50000/50000 [==============================] - 41s 816us/step - loss: 0.2482 - acc: 0.8882 - val_loss: 0.3622 - val_acc: 0.8472\n",
      "Epoch 46/150\n",
      "50000/50000 [==============================] - 39s 788us/step - loss: 0.2505 - acc: 0.8875 - val_loss: 0.3584 - val_acc: 0.8483\n",
      "Epoch 47/150\n",
      "50000/50000 [==============================] - 39s 789us/step - loss: 0.2475 - acc: 0.8887 - val_loss: 0.3933 - val_acc: 0.8419\n",
      "Epoch 48/150\n",
      "50000/50000 [==============================] - 39s 789us/step - loss: 0.2438 - acc: 0.8908 - val_loss: 0.3608 - val_acc: 0.8462\n",
      "Epoch 49/150\n",
      "50000/50000 [==============================] - 39s 787us/step - loss: 0.2422 - acc: 0.8919 - val_loss: 0.3961 - val_acc: 0.8370\n",
      "Epoch 50/150\n",
      "50000/50000 [==============================] - 40s 793us/step - loss: 0.2365 - acc: 0.8934 - val_loss: 0.4083 - val_acc: 0.8430\n",
      "Epoch 51/150\n",
      "50000/50000 [==============================] - 40s 792us/step - loss: 0.2370 - acc: 0.8938 - val_loss: 0.3638 - val_acc: 0.8488\n",
      "Epoch 52/150\n",
      "50000/50000 [==============================] - 39s 779us/step - loss: 0.2376 - acc: 0.8940 - val_loss: 0.3997 - val_acc: 0.8328\n",
      "Epoch 53/150\n",
      "50000/50000 [==============================] - 39s 777us/step - loss: 0.2355 - acc: 0.8939 - val_loss: 0.3603 - val_acc: 0.8481\n",
      "Epoch 54/150\n",
      "50000/50000 [==============================] - 39s 777us/step - loss: 0.2318 - acc: 0.8958 - val_loss: 0.4337 - val_acc: 0.8358\n",
      "Epoch 55/150\n",
      "50000/50000 [==============================] - 39s 778us/step - loss: 0.2325 - acc: 0.8973 - val_loss: 0.3847 - val_acc: 0.8429\n",
      "Epoch 56/150\n",
      "50000/50000 [==============================] - 39s 780us/step - loss: 0.2279 - acc: 0.8986 - val_loss: 0.3738 - val_acc: 0.8444\n",
      "Epoch 57/150\n",
      "50000/50000 [==============================] - 39s 776us/step - loss: 0.2288 - acc: 0.8982 - val_loss: 0.3750 - val_acc: 0.8463\n",
      "Epoch 58/150\n",
      "50000/50000 [==============================] - 39s 778us/step - loss: 0.2267 - acc: 0.8999 - val_loss: 0.3858 - val_acc: 0.8479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150\n",
      "50000/50000 [==============================] - 39s 775us/step - loss: 0.2258 - acc: 0.9001 - val_loss: 0.3746 - val_acc: 0.8512\n",
      "Epoch 60/150\n",
      "50000/50000 [==============================] - 39s 773us/step - loss: 0.2265 - acc: 0.8995 - val_loss: 0.3875 - val_acc: 0.8484\n",
      "Epoch 61/150\n",
      "50000/50000 [==============================] - 39s 774us/step - loss: 0.2203 - acc: 0.9032 - val_loss: 0.3970 - val_acc: 0.8525\n",
      "Epoch 62/150\n",
      "50000/50000 [==============================] - 39s 774us/step - loss: 0.2218 - acc: 0.9019 - val_loss: 0.3839 - val_acc: 0.8416\n",
      "Epoch 63/150\n",
      "50000/50000 [==============================] - 39s 774us/step - loss: 0.2198 - acc: 0.9032 - val_loss: 0.3958 - val_acc: 0.8462\n",
      "Epoch 64/150\n",
      "50000/50000 [==============================] - 39s 772us/step - loss: 0.2175 - acc: 0.9039 - val_loss: 0.4083 - val_acc: 0.8465\n",
      "Epoch 65/150\n",
      "50000/50000 [==============================] - 39s 774us/step - loss: 0.2155 - acc: 0.9054 - val_loss: 0.3771 - val_acc: 0.8470\n",
      "Epoch 66/150\n",
      "50000/50000 [==============================] - 39s 783us/step - loss: 0.2143 - acc: 0.9072 - val_loss: 0.3905 - val_acc: 0.8452\n",
      "Epoch 67/150\n",
      "50000/50000 [==============================] - 39s 773us/step - loss: 0.2153 - acc: 0.9065 - val_loss: 0.3914 - val_acc: 0.8483\n",
      "Epoch 68/150\n",
      "50000/50000 [==============================] - 39s 773us/step - loss: 0.2112 - acc: 0.9082 - val_loss: 0.4367 - val_acc: 0.8389\n",
      "Epoch 69/150\n",
      "50000/50000 [==============================] - 39s 773us/step - loss: 0.2104 - acc: 0.9085 - val_loss: 0.4010 - val_acc: 0.8430\n",
      "Epoch 70/150\n",
      "50000/50000 [==============================] - 39s 772us/step - loss: 0.2121 - acc: 0.9068 - val_loss: 0.4137 - val_acc: 0.8444\n",
      "Epoch 71/150\n",
      "50000/50000 [==============================] - 39s 772us/step - loss: 0.2070 - acc: 0.9103 - val_loss: 0.3852 - val_acc: 0.8516\n",
      "Epoch 72/150\n",
      "50000/50000 [==============================] - 39s 772us/step - loss: 0.2040 - acc: 0.9113 - val_loss: 0.3983 - val_acc: 0.8461\n",
      "Epoch 73/150\n",
      "50000/50000 [==============================] - 39s 771us/step - loss: 0.2039 - acc: 0.9117 - val_loss: 0.4167 - val_acc: 0.8453\n",
      "Epoch 74/150\n",
      "50000/50000 [==============================] - 39s 774us/step - loss: 0.2049 - acc: 0.9112 - val_loss: 0.4358 - val_acc: 0.8459\n",
      "Epoch 75/150\n",
      "50000/50000 [==============================] - 39s 777us/step - loss: 0.2024 - acc: 0.9129 - val_loss: 0.4283 - val_acc: 0.8428\n",
      "Epoch 76/150\n",
      "50000/50000 [==============================] - 39s 772us/step - loss: 0.1998 - acc: 0.9131 - val_loss: 0.3949 - val_acc: 0.8466\n",
      "Epoch 77/150\n",
      "50000/50000 [==============================] - 39s 773us/step - loss: 0.1968 - acc: 0.9139 - val_loss: 0.4204 - val_acc: 0.8462\n",
      "Epoch 78/150\n",
      "50000/50000 [==============================] - 39s 774us/step - loss: 0.1978 - acc: 0.9157 - val_loss: 0.4221 - val_acc: 0.8430\n",
      "Epoch 79/150\n",
      "50000/50000 [==============================] - 39s 772us/step - loss: 0.1987 - acc: 0.9147 - val_loss: 0.4100 - val_acc: 0.8490\n",
      "Epoch 80/150\n",
      "50000/50000 [==============================] - 39s 776us/step - loss: 0.1923 - acc: 0.9185 - val_loss: 0.4118 - val_acc: 0.8474\n",
      "Epoch 81/150\n",
      "50000/50000 [==============================] - 39s 773us/step - loss: 0.1970 - acc: 0.9155 - val_loss: 0.4309 - val_acc: 0.8486\n",
      "Epoch 82/150\n",
      "50000/50000 [==============================] - 39s 775us/step - loss: 0.1916 - acc: 0.9178 - val_loss: 0.4178 - val_acc: 0.8448\n",
      "Epoch 83/150\n",
      "50000/50000 [==============================] - 39s 774us/step - loss: 0.1942 - acc: 0.9172 - val_loss: 0.4062 - val_acc: 0.8426\n",
      "Epoch 84/150\n",
      "50000/50000 [==============================] - 39s 777us/step - loss: 0.1917 - acc: 0.9178 - val_loss: 0.4151 - val_acc: 0.8464\n",
      "Epoch 85/150\n",
      "50000/50000 [==============================] - 39s 773us/step - loss: 0.1894 - acc: 0.9188 - val_loss: 0.3945 - val_acc: 0.8521\n",
      "Epoch 86/150\n",
      "50000/50000 [==============================] - 39s 775us/step - loss: 0.1891 - acc: 0.9197 - val_loss: 0.4274 - val_acc: 0.8446\n",
      "Epoch 87/150\n",
      "50000/50000 [==============================] - 39s 777us/step - loss: 0.1905 - acc: 0.9179 - val_loss: 0.4178 - val_acc: 0.8453\n",
      "Epoch 88/150\n",
      "50000/50000 [==============================] - 39s 774us/step - loss: 0.1877 - acc: 0.9199 - val_loss: 0.4652 - val_acc: 0.8403\n",
      "Epoch 89/150\n",
      "50000/50000 [==============================] - 39s 781us/step - loss: 0.1827 - acc: 0.9225 - val_loss: 0.4286 - val_acc: 0.8474\n",
      "Epoch 90/150\n",
      "50000/50000 [==============================] - 39s 776us/step - loss: 0.1823 - acc: 0.9221 - val_loss: 0.4837 - val_acc: 0.8337\n",
      "Epoch 91/150\n",
      "50000/50000 [==============================] - 39s 776us/step - loss: 0.1832 - acc: 0.9225 - val_loss: 0.4280 - val_acc: 0.8446\n",
      "Epoch 92/150\n",
      "50000/50000 [==============================] - 39s 775us/step - loss: 0.1813 - acc: 0.9229 - val_loss: 0.4778 - val_acc: 0.8394\n",
      "Epoch 93/150\n",
      "50000/50000 [==============================] - 39s 776us/step - loss: 0.1872 - acc: 0.9220 - val_loss: 0.4625 - val_acc: 0.8434\n",
      "Epoch 94/150\n",
      "50000/50000 [==============================] - 39s 776us/step - loss: 0.1803 - acc: 0.9263 - val_loss: 0.4269 - val_acc: 0.8453\n",
      "Epoch 95/150\n",
      "50000/50000 [==============================] - 39s 775us/step - loss: 0.1780 - acc: 0.9261 - val_loss: 0.4685 - val_acc: 0.8402\n",
      "Epoch 96/150\n",
      "50000/50000 [==============================] - 39s 776us/step - loss: 0.1800 - acc: 0.9248 - val_loss: 0.4429 - val_acc: 0.8444\n",
      "Epoch 97/150\n",
      "50000/50000 [==============================] - 39s 777us/step - loss: 0.1737 - acc: 0.9269 - val_loss: 0.4748 - val_acc: 0.8458\n",
      "Epoch 98/150\n",
      "50000/50000 [==============================] - 39s 779us/step - loss: 0.1765 - acc: 0.9269 - val_loss: 0.4704 - val_acc: 0.8482\n",
      "Epoch 99/150\n",
      "50000/50000 [==============================] - 39s 777us/step - loss: 0.1709 - acc: 0.9269 - val_loss: 0.4501 - val_acc: 0.8462\n",
      "Epoch 100/150\n",
      "50000/50000 [==============================] - 39s 777us/step - loss: 0.1728 - acc: 0.9281 - val_loss: 0.4468 - val_acc: 0.8489\n",
      "Epoch 101/150\n",
      "50000/50000 [==============================] - 39s 777us/step - loss: 0.1703 - acc: 0.9283 - val_loss: 0.4815 - val_acc: 0.8435\n",
      "Epoch 102/150\n",
      "50000/50000 [==============================] - 39s 775us/step - loss: 0.1704 - acc: 0.9291 - val_loss: 0.4673 - val_acc: 0.8457\n",
      "Epoch 103/150\n",
      "50000/50000 [==============================] - 39s 779us/step - loss: 0.1706 - acc: 0.9287 - val_loss: 0.4655 - val_acc: 0.8471\n",
      "Epoch 104/150\n",
      "50000/50000 [==============================] - 39s 775us/step - loss: 0.1695 - acc: 0.9279 - val_loss: 0.4770 - val_acc: 0.8464\n",
      "Epoch 105/150\n",
      "50000/50000 [==============================] - 39s 777us/step - loss: 0.1715 - acc: 0.9283 - val_loss: 0.4588 - val_acc: 0.8494\n",
      "Epoch 106/150\n",
      "50000/50000 [==============================] - 39s 775us/step - loss: 0.1686 - acc: 0.9311 - val_loss: 0.4548 - val_acc: 0.8467\n",
      "Epoch 107/150\n",
      "50000/50000 [==============================] - 39s 777us/step - loss: 0.1711 - acc: 0.9287 - val_loss: 0.4778 - val_acc: 0.8358\n",
      "Epoch 108/150\n",
      "50000/50000 [==============================] - 39s 776us/step - loss: 0.1665 - acc: 0.9305 - val_loss: 0.4445 - val_acc: 0.8398\n",
      "Epoch 109/150\n",
      "50000/50000 [==============================] - 39s 776us/step - loss: 0.1660 - acc: 0.9327 - val_loss: 0.5001 - val_acc: 0.8458\n",
      "Epoch 110/150\n",
      "50000/50000 [==============================] - 39s 775us/step - loss: 0.1643 - acc: 0.9327 - val_loss: 0.4720 - val_acc: 0.8481\n",
      "Epoch 111/150\n",
      "50000/50000 [==============================] - 39s 775us/step - loss: 0.1658 - acc: 0.9319 - val_loss: 0.4966 - val_acc: 0.8465\n",
      "Epoch 112/150\n",
      "50000/50000 [==============================] - 39s 781us/step - loss: 0.1655 - acc: 0.9313 - val_loss: 0.4676 - val_acc: 0.8444\n",
      "Epoch 113/150\n",
      "50000/50000 [==============================] - 39s 779us/step - loss: 0.1612 - acc: 0.9351 - val_loss: 0.4655 - val_acc: 0.8501\n",
      "Epoch 114/150\n",
      "50000/50000 [==============================] - 39s 779us/step - loss: 0.1649 - acc: 0.9333 - val_loss: 0.4673 - val_acc: 0.8491\n",
      "Epoch 115/150\n",
      "50000/50000 [==============================] - 39s 778us/step - loss: 0.1669 - acc: 0.9317 - val_loss: 0.4582 - val_acc: 0.8455\n",
      "Epoch 116/150\n",
      "50000/50000 [==============================] - 39s 774us/step - loss: 0.1617 - acc: 0.9335 - val_loss: 0.4611 - val_acc: 0.8513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/150\n",
      "50000/50000 [==============================] - 39s 774us/step - loss: 0.1583 - acc: 0.9355 - val_loss: 0.4919 - val_acc: 0.8498\n",
      "Epoch 118/150\n",
      "50000/50000 [==============================] - 39s 771us/step - loss: 0.1593 - acc: 0.9352 - val_loss: 0.4739 - val_acc: 0.8479\n",
      "Epoch 119/150\n",
      "50000/50000 [==============================] - 38s 769us/step - loss: 0.1564 - acc: 0.9362 - val_loss: 0.4772 - val_acc: 0.8481\n",
      "Epoch 120/150\n",
      "50000/50000 [==============================] - 40s 791us/step - loss: 0.1548 - acc: 0.9359 - val_loss: 0.5034 - val_acc: 0.8481\n",
      "Epoch 121/150\n",
      "50000/50000 [==============================] - 39s 777us/step - loss: 0.1560 - acc: 0.9363 - val_loss: 0.5012 - val_acc: 0.8490\n",
      "Epoch 122/150\n",
      "50000/50000 [==============================] - 39s 771us/step - loss: 0.1535 - acc: 0.9370 - val_loss: 0.4515 - val_acc: 0.8441\n",
      "Epoch 123/150\n",
      "50000/50000 [==============================] - 39s 770us/step - loss: 0.1523 - acc: 0.9380 - val_loss: 0.4802 - val_acc: 0.8493\n",
      "Epoch 124/150\n",
      "50000/50000 [==============================] - 39s 772us/step - loss: 0.1561 - acc: 0.9371 - val_loss: 0.4951 - val_acc: 0.8503\n",
      "Epoch 125/150\n",
      "50000/50000 [==============================] - 39s 772us/step - loss: 0.1565 - acc: 0.9371 - val_loss: 0.5043 - val_acc: 0.8485\n",
      "Epoch 126/150\n",
      "50000/50000 [==============================] - 39s 776us/step - loss: 0.1514 - acc: 0.9376 - val_loss: 0.5174 - val_acc: 0.8500\n",
      "Epoch 127/150\n",
      "50000/50000 [==============================] - 39s 772us/step - loss: 0.1532 - acc: 0.9382 - val_loss: 0.5048 - val_acc: 0.8477\n",
      "Epoch 128/150\n",
      "50000/50000 [==============================] - 39s 775us/step - loss: 0.1507 - acc: 0.9390 - val_loss: 0.4936 - val_acc: 0.8499\n",
      "Epoch 129/150\n",
      "50000/50000 [==============================] - 39s 771us/step - loss: 0.1483 - acc: 0.9395 - val_loss: 0.5014 - val_acc: 0.8453\n",
      "Epoch 130/150\n",
      "50000/50000 [==============================] - 39s 772us/step - loss: 0.1520 - acc: 0.9382 - val_loss: 0.5285 - val_acc: 0.8464\n",
      "Epoch 131/150\n",
      "50000/50000 [==============================] - 39s 775us/step - loss: 0.1465 - acc: 0.9415 - val_loss: 0.4818 - val_acc: 0.8506\n",
      "Epoch 132/150\n",
      "50000/50000 [==============================] - 39s 772us/step - loss: 0.1463 - acc: 0.9417 - val_loss: 0.5099 - val_acc: 0.8468\n",
      "Epoch 133/150\n",
      "50000/50000 [==============================] - 39s 772us/step - loss: 0.1448 - acc: 0.9421 - val_loss: 0.5630 - val_acc: 0.8481\n",
      "Epoch 134/150\n",
      "50000/50000 [==============================] - 39s 774us/step - loss: 0.1466 - acc: 0.9410 - val_loss: 0.5293 - val_acc: 0.8482\n",
      "Epoch 135/150\n",
      "50000/50000 [==============================] - 39s 776us/step - loss: 0.1438 - acc: 0.9427 - val_loss: 0.5106 - val_acc: 0.8478\n",
      "Epoch 136/150\n",
      "50000/50000 [==============================] - 39s 775us/step - loss: 0.1436 - acc: 0.9429 - val_loss: 0.5132 - val_acc: 0.8497\n",
      "Epoch 137/150\n",
      "50000/50000 [==============================] - 39s 776us/step - loss: 0.1439 - acc: 0.9422 - val_loss: 0.5316 - val_acc: 0.8510\n",
      "Epoch 138/150\n",
      "50000/50000 [==============================] - 39s 779us/step - loss: 0.1428 - acc: 0.9431 - val_loss: 0.5241 - val_acc: 0.8460\n",
      "Epoch 139/150\n",
      "50000/50000 [==============================] - 39s 773us/step - loss: 0.1382 - acc: 0.9448 - val_loss: 0.5725 - val_acc: 0.8467\n",
      "Epoch 140/150\n",
      "50000/50000 [==============================] - 39s 780us/step - loss: 0.1374 - acc: 0.9433 - val_loss: 0.5432 - val_acc: 0.8468\n",
      "Epoch 141/150\n",
      "50000/50000 [==============================] - 39s 774us/step - loss: 0.1407 - acc: 0.9428 - val_loss: 0.5163 - val_acc: 0.8439\n",
      "Epoch 142/150\n",
      "50000/50000 [==============================] - 39s 773us/step - loss: 0.1433 - acc: 0.9424 - val_loss: 0.5568 - val_acc: 0.8499\n",
      "Epoch 143/150\n",
      "50000/50000 [==============================] - 39s 775us/step - loss: 0.1420 - acc: 0.9420 - val_loss: 0.5643 - val_acc: 0.8470\n",
      "Epoch 144/150\n",
      "50000/50000 [==============================] - 39s 776us/step - loss: 0.1381 - acc: 0.9441 - val_loss: 0.5491 - val_acc: 0.8478\n",
      "Epoch 145/150\n",
      "50000/50000 [==============================] - 39s 780us/step - loss: 0.1377 - acc: 0.9447 - val_loss: 0.5621 - val_acc: 0.8522\n",
      "Epoch 146/150\n",
      "50000/50000 [==============================] - 39s 775us/step - loss: 0.1378 - acc: 0.9451 - val_loss: 0.5219 - val_acc: 0.8430\n",
      "Epoch 147/150\n",
      "50000/50000 [==============================] - 39s 777us/step - loss: 0.1364 - acc: 0.9449 - val_loss: 0.5405 - val_acc: 0.8390\n",
      "Epoch 148/150\n",
      "50000/50000 [==============================] - 39s 775us/step - loss: 0.1357 - acc: 0.9455 - val_loss: 0.5165 - val_acc: 0.8478\n",
      "Epoch 149/150\n",
      "50000/50000 [==============================] - 39s 780us/step - loss: 0.1367 - acc: 0.9455 - val_loss: 0.5347 - val_acc: 0.8495\n",
      "Epoch 150/150\n",
      "50000/50000 [==============================] - 39s 776us/step - loss: 0.1387 - acc: 0.9445 - val_loss: 0.5214 - val_acc: 0.8443\n",
      "Accuracy: 84.43%\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=16)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_set_images/pred_1.png\n",
      "test_set_images/pred_2.png\n",
      "test_set_images/pred_3.png\n",
      "test_set_images/pred_4.png\n",
      "test_set_images/pred_5.png\n",
      "test_set_images/pred_6.png\n",
      "test_set_images/pred_7.png\n",
      "test_set_images/pred_8.png\n",
      "test_set_images/pred_9.png\n",
      "test_set_images/pred_10.png\n",
      "test_set_images/pred_11.png\n",
      "test_set_images/pred_12.png\n",
      "test_set_images/pred_13.png\n",
      "test_set_images/pred_14.png\n",
      "test_set_images/pred_15.png\n",
      "test_set_images/pred_16.png\n",
      "test_set_images/pred_17.png\n",
      "test_set_images/pred_18.png\n",
      "test_set_images/pred_19.png\n",
      "test_set_images/pred_20.png\n",
      "test_set_images/pred_21.png\n",
      "test_set_images/pred_22.png\n",
      "test_set_images/pred_23.png\n",
      "test_set_images/pred_24.png\n",
      "test_set_images/pred_25.png\n",
      "test_set_images/pred_26.png\n",
      "test_set_images/pred_27.png\n",
      "test_set_images/pred_28.png\n",
      "test_set_images/pred_29.png\n",
      "test_set_images/pred_30.png\n",
      "test_set_images/pred_31.png\n",
      "test_set_images/pred_32.png\n",
      "test_set_images/pred_33.png\n",
      "test_set_images/pred_34.png\n",
      "test_set_images/pred_35.png\n",
      "test_set_images/pred_36.png\n",
      "test_set_images/pred_37.png\n",
      "test_set_images/pred_38.png\n",
      "test_set_images/pred_39.png\n",
      "test_set_images/pred_40.png\n",
      "test_set_images/pred_41.png\n",
      "test_set_images/pred_42.png\n",
      "test_set_images/pred_43.png\n",
      "test_set_images/pred_44.png\n",
      "test_set_images/pred_45.png\n",
      "test_set_images/pred_46.png\n",
      "test_set_images/pred_47.png\n",
      "test_set_images/pred_48.png\n",
      "test_set_images/pred_49.png\n",
      "test_set_images/pred_50.png\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def label_to_img(imgwidth, imgheight, w, h, labels):\n",
    "    array_labels = numpy.zeros([imgwidth, imgheight])\n",
    "    idx = 0\n",
    "    for i in range(0,imgheight,h):\n",
    "        for j in range(0,imgwidth,w):\n",
    "            if labels[idx][0] > 0.5:\n",
    "                l = 0\n",
    "            else:\n",
    "                l = 1\n",
    "            array_labels[j:j+w, i:i+h] = l\n",
    "            idx = idx + 1\n",
    "    return array_labels\n",
    "\n",
    "def concatenate_images(img, gt_img):\n",
    "    nChannels = len(gt_img.shape)\n",
    "    w = gt_img.shape[0]\n",
    "    h = gt_img.shape[1]\n",
    "    if nChannels == 3:\n",
    "        cimg = numpy.concatenate((img, gt_img), axis=1)\n",
    "    else:\n",
    "        gt_img_3c = numpy.zeros((w, h, 3), dtype=numpy.uint8)\n",
    "        gt_img8 = img_float_to_uint8(gt_img)          \n",
    "        gt_img_3c[:,:,0] = gt_img8\n",
    "        gt_img_3c[:,:,1] = gt_img8\n",
    "        gt_img_3c[:,:,2] = gt_img8\n",
    "        img8 = img_float_to_uint8(img)\n",
    "        cimg = numpy.concatenate((img8, gt_img_3c), axis=1)\n",
    "    return cimg\n",
    "\n",
    "def bw(gt_img):\n",
    "    nChannels = len(gt_img.shape)\n",
    "    w = gt_img.shape[0]\n",
    "    h = gt_img.shape[1]\n",
    "    if nChannels == 3:\n",
    "        cimg = gt_img #np.concatenate((img, gt_img), axis=1)\n",
    "    else:\n",
    "        gt_img_3c = np.zeros((w, h, 3), dtype=np.uint8)\n",
    "        gt_img8 = img_float_to_uint8(gt_img)          \n",
    "        gt_img_3c[:,:,0] = gt_img8\n",
    "        gt_img_3c[:,:,1] = gt_img8\n",
    "        gt_img_3c[:,:,2] = gt_img8\n",
    "        cimg = gt_img_3c\n",
    "    return cimg\n",
    "\n",
    "    # Get prediction for given input image \n",
    "def get_prediction(img):\n",
    "    data = numpy.asarray(img_crop(img, IMG_PATCH_SIZE, IMG_PATCH_SIZE))\n",
    "    output_prediction = model.predict(data)\n",
    "    img_prediction = label_to_img(img.shape[0], img.shape[1], IMG_PATCH_SIZE, IMG_PATCH_SIZE, output_prediction)\n",
    "\n",
    "    return img_prediction\n",
    "\n",
    "    # Get a concatenation of the prediction and groundtruth for given input file\n",
    "def get_prediction_with_groundtruth(filename, image_idx):\n",
    "    \n",
    "    imageid = \"test_\" + str(image_idx)\n",
    "    image_filename = filename + imageid + \".png\"\n",
    "    img = mpimg.imread(image_filename)\n",
    "    \n",
    "    img_prediction = get_prediction(img)\n",
    "    #cimg = concatenate_images(img, img_prediction)\n",
    "    #cimg = Image.fromarray(bw(img_prediction))\n",
    "\n",
    "    #return cimg\n",
    "    return img_prediction\n",
    "\n",
    "submission_filename = 'submission.csv'\n",
    "image_filenames = []\n",
    "\n",
    "for i in range(1, 51):\n",
    "    'test_set_images/test_'\n",
    "    test_data_filename = 'test_set_images/test_' + str(i) + '/'\n",
    "    pimg = get_prediction_with_groundtruth(test_data_filename, i)\n",
    "    image_filename = 'test_set_images/pred_' + str(i) + '.png'\n",
    "    Image.fromarray(bw(pimg)).save(image_filename)\n",
    "    print(image_filename)\n",
    "    image_filenames.append(image_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mask_to_submission import *\n",
    "masks_to_submission(submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
